{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone --branch part2-mel https://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@github.com/amiralichangizi/Affordance3DHighlighter.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2rqJobuCpQLi","outputId":"281b69ef-7d5c-40e7-e9d1-c343706616ea","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:22:56.405013Z","iopub.execute_input":"2024-12-29T13:22:56.405362Z","iopub.status.idle":"2024-12-29T13:22:57.472712Z","shell.execute_reply.started":"2024-12-29T13:22:56.405331Z","shell.execute_reply":"2024-12-29T13:22:57.471524Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Affordance3DHighlighter'...\nremote: Enumerating objects: 141, done.\u001b[K\nremote: Counting objects: 100% (141/141), done.\u001b[K\nremote: Compressing objects: 100% (99/99), done.\u001b[K\nremote: Total 141 (delta 75), reused 103 (delta 39), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (141/141), 1.84 MiB | 23.24 MiB/s, done.\nResolving deltas: 100% (75/75), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\nos.chdir('/kaggle/working/Affordance3DHighlighter')","metadata":{"id":"fhLYzi952EEA","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:23:00.657241Z","iopub.execute_input":"2024-12-29T13:23:00.657572Z","iopub.status.idle":"2024-12-29T13:23:00.661274Z","shell.execute_reply.started":"2024-12-29T13:23:00.657544Z","shell.execute_reply":"2024-12-29T13:23:00.660466Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"!pip install git+https://github.com/openai/CLIP.git\n!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8vCbctxbPP4","outputId":"55a100ed-7b85-4630-9e3f-e3ce98c37fff","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:24:23.588319Z","iopub.execute_input":"2024-12-29T13:24:23.588989Z","iopub.status.idle":"2024-12-29T13:24:31.831852Z","shell.execute_reply.started":"2024-12-29T13:24:23.588955Z","shell.execute_reply":"2024-12-29T13:24:31.830950Z"}},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-35_4t8fm\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-35_4t8fm\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (6.3.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.9.11)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.5)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.19.1+cu121)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\nLooking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html\nRequirement already satisfied: kaolin==0.17.0 in /usr/local/lib/python3.10/dist-packages (0.17.0)\nRequirement already satisfied: ipycanvas in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (0.13.3)\nRequirement already satisfied: ipyevents in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.0.2)\nRequirement already satisfied: jupyter-client<8 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (7.4.9)\nRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.2.5)\nRequirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (6.3.3)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (0.2.2)\nRequirement already satisfied: usd-core in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (24.11)\nRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.26.4)\nRequirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.13.6)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (10.4.0)\nRequirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (4.66.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.13.1)\nRequirement already satisfied: pygltflib in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.16.3)\nRequirement already satisfied: warp-lang in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.5.0)\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (7.34.0)\nRequirement already satisfied: traitlets>=4 in /usr/local/lib/python3.10/dist-packages (from comm>=0.1.3->kaolin==0.17.0) (5.7.1)\nRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (0.4)\nRequirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.7.2)\nRequirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (1.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (2.8.2)\nRequirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (24.0.1)\nRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.0.4)\nRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (2.2.0)\nRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (8.1.7)\nRequirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.10/dist-packages (from ipycanvas->kaolin==0.17.0) (8.1.5)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (71.0.4)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (3.0.47)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.9.0)\nRequirement already satisfied: dataclasses-json>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.17.0) (0.6.7)\nRequirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.17.0) (1.2.15)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (3.23.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (0.9.0)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.0.13)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kaolin==0.17.0) (0.8.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->kaolin==0.17.0) (2.1.5)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.9.2->jupyter-client<8->kaolin==0.17.0) (4.3.6)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kaolin==0.17.0) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kaolin==0.17.0) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter-client<8->kaolin==0.17.0) (1.16.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygltflib->kaolin==0.17.0) (1.16.0)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (24.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (1.0.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (4.12.2)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"\nimport sys\nimport torch\n\nneed_pytorch3d = False\ntry:\n    import pytorch3d\nexcept ModuleNotFoundError:\n    need_pytorch3d = True\nif need_pytorch3d:\n    pyt_version_str = torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n    version_str = \"\".join([\n        f\"py3{sys.version_info.minor}_cu\",\n        torch.version.cuda.replace(\".\", \"\"),\n        f\"_pyt{pyt_version_str}\"\n    ])\n    !pip install iopath\n    if sys.platform.startswith(\"linux\"):\n        print(\"Trying to install wheel for PyTorch3D\")\n        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n        pip_list = !pip freeze\n        need_pytorch3d = not any(i.startswith(\"pytorch3d==\") for i in pip_list)\n    if need_pytorch3d:\n        print(f\"failed to find/install wheel for {version_str}\")\nif need_pytorch3d:\n    print(\"Installing PyTorch3D from source\")\n    !pip install ninja\n    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sRNWfRMnIzuJ","outputId":"39ed1f77-3f8e-499d-eb2b-8aecadf7c335","ExecuteTime":{"end_time":"2024-12-26T14:58:53.585274Z","start_time":"2024-12-26T14:58:48.836644Z"},"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:25:20.703998Z","iopub.execute_input":"2024-12-29T14:25:20.704313Z","iopub.status.idle":"2024-12-29T14:25:20.715992Z","shell.execute_reply.started":"2024-12-29T14:25:20.704290Z","shell.execute_reply":"2024-12-29T14:25:20.715196Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"!pip install open3d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zT9LfpcRXDHy","outputId":"527d847c-60da-4e72-c096-81cbf9671f92","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:25:35.004942Z","iopub.execute_input":"2024-12-29T13:25:35.005268Z","iopub.status.idle":"2024-12-29T13:25:52.711356Z","shell.execute_reply.started":"2024-12-29T13:25:35.005248Z","shell.execute_reply":"2024-12-29T13:25:52.710373Z"}},"outputs":[{"name":"stdout","text":"Collecting open3d\n  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.26.4)\nCollecting dash>=2.6.0 (from open3d)\n  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.4)\nRequirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\nCollecting configargparse (from open3d)\n  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from open3d) (8.1.5)\nCollecting addict (from open3d)\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (10.4.0)\nRequirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\nRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.1.4)\nRequirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.2)\nRequirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.5)\nCollecting pyquaternion (from open3d)\n  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\nRequirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\nCollecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.5.0)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\nCollecting retrying (from dash>=2.6.0->open3d)\n  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (71.0.4)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.20.0)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.23.0)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\nRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\nRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.47)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.20.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.20.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.8.30)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\nDownloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\nDownloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\nDownloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\nDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\nDownloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\nDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\nInstalling collected packages: dash-table, dash-html-components, dash-core-components, addict, retrying, pyquaternion, configargparse, dash, open3d\nSuccessfully installed addict-2.4.0 configargparse-1.7 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"!mkdir -p data/PittsburghBridge\n!wget -P data/PittsburghBridge https://dl.fbaipublicfiles.com/pytorch3d/data/PittsburghBridge/pointcloud.npz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FTk44DGYYIBS","outputId":"864b8bfd-a638-4f09-f520-d3f0fb75389c","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T13:17:38.518502Z","iopub.execute_input":"2024-12-29T13:17:38.518795Z","iopub.status.idle":"2024-12-29T13:17:38.949273Z","shell.execute_reply.started":"2024-12-29T13:17:38.518773Z","shell.execute_reply":"2024-12-29T13:17:38.948438Z"}},"outputs":[{"name":"stdout","text":"--2024-12-29 13:17:38--  https://dl.fbaipublicfiles.com/pytorch3d/data/PittsburghBridge/pointcloud.npz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 3.163.189.51, 3.163.189.14, 3.163.189.96, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|3.163.189.51|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5701352 (5.4M) [application/zip]\nSaving to: ‘data/PittsburghBridge/pointcloud.npz’\n\npointcloud.npz      100%[===================>]   5.44M  --.-KB/s    in 0.09s   \n\n2024-12-29 13:17:38 (58.6 MB/s) - ‘data/PittsburghBridge/pointcloud.npz’ saved [5701352/5701352]\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"\nfrom src.mesh import Mesh\nfrom pytorch3d.structures import Pointclouds\n\nfrom src.convertor import obj_to_pointcloud\n\n\ndef bounding_sphere_normalize(points: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    points: (N,3) tensor of point coords\n    Return normalized points in a unit sphere centered at origin.\n    \"\"\"\n    center = points.mean(dim=0, keepdim=True)\n    max_dist = (points - center).norm(p=2, dim=1).max()\n    points_normed = (points - center) / max_dist\n    return points_normed\n\n\ndef load_3d_data(file_path, num_points=10000, device=\"cuda\", do_normalize=True):\n    \"\"\"\n    Loads 3D data as PyTorch3D Pointclouds from either NPZ point cloud or OBJ mesh.\n\n    Args:\n        file_path: Path to either .npz point cloud or .obj mesh file\n        num_points: Number of points to sample if loading from mesh\n        device: Device to load data on\n\n    Returns:\n        Pointclouds object containing points and features\n    \"\"\"\n    file_ext = file_path.split('.')[-1].lower()\n\n    if file_ext == 'npz':\n        # Load NPZ point cloud directly like in the example\n        pointcloud = np.load(file_path)\n        verts = torch.Tensor(pointcloud['verts']).to(device)\n        rgb = torch.Tensor(pointcloud['rgb']).to(device)\n\n        print(\"lenght of the data\")\n        print(len(verts))\n\n        # Subsample if needed\n        if len(verts) > num_points:\n            idx = torch.randperm(len(verts))[:num_points]\n            verts = verts[idx]\n            rgb = rgb[idx]\n\n        if do_normalize:\n            verts = bounding_sphere_normalize(verts)\n\n        # Return both the points tensor and the Pointclouds object\n        point_cloud = Pointclouds(points=[verts], features=[rgb])\n        return verts, point_cloud  # Return both\n\n    elif file_ext == 'obj':\n        # Load and convert your OBJ file\n        points, point_cloud = obj_to_pointcloud(\n            file_path,\n            num_points=num_points,  # Adjust this number as needed\n            device=\"cuda\"  # Use \"cpu\" if you don't have a GPU\n        )\n        if do_normalize:\n            points = bounding_sphere_normalize(points)\n            # here we update the point cloud too\n            rgb = point_cloud.features_packed() # shape [N,3]\n            point_cloud = Pointclouds(points = [points], features = [rgb])\n        return points, point_cloud\n        # # Load mesh and sample points\n        # mesh = Mesh(file_path)\n        # vertices = mesh.vertices\n\n        # # Sample random points\n        # idx = torch.randperm(vertices.shape[0])[:num_points]\n        # points = vertices[idx].to(device)\n\n        # # Initialize with gray color\n        # colors = torch.ones_like(points) * 0.7\n\n        # return Pointclouds(points=[points], features=[colors])\n\n    else:\n        raise ValueError(f\"Unsupported file format: {file_ext}. Only .npz and .obj are supported.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:25:27.631412Z","iopub.execute_input":"2024-12-29T14:25:27.631711Z","iopub.status.idle":"2024-12-29T14:25:27.639712Z","shell.execute_reply.started":"2024-12-29T14:25:27.631688Z","shell.execute_reply":"2024-12-29T14:25:27.638779Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def print_grad_fn(tensor, depth=0):\n    \"\"\"Recursively print the gradient function graph\"\"\"\n    if tensor.grad_fn is None:\n        print(\"  \" * depth + \"None (leaf tensor)\")\n        return\n\n    print(\"  \" * depth + str(tensor.grad_fn))\n    for fn in tensor.grad_fn.next_functions:\n        if fn[0] is not None:\n            print(\"  \" * (depth + 1) + str(fn[0]))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:25:41.677027Z","iopub.execute_input":"2024-12-29T14:25:41.677365Z","iopub.status.idle":"2024-12-29T14:25:41.682294Z","shell.execute_reply.started":"2024-12-29T14:25:41.677336Z","shell.execute_reply":"2024-12-29T14:25:41.681359Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"\nfrom src.render.cloud_point_renderer import MultiViewPointCloudRenderer\nfrom src.save_results import save_renders, save_results\nfrom src.neural_highlighter import NeuralHighlighter\nfrom src.Clip.loss_function import clip_loss\nfrom src.Clip.clip_model import get_clip_model, encode_text, setup_clip_transforms\n\nimport torch\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\n# Constrain most sources of randomness\n# (some torch backwards functions within CLIP are non-determinstic)\n# Set a consistent seed for reproducibility\nseed = 0  # You can use any integer value\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n\n\ndef optimize_point_cloud(points, clip_model, renderer, encoded_text, log_dir: str, **kwargs):\n    num_iterations = kwargs.get('num_iterations', 1000)\n    learning_rate = kwargs.get('learning_rate', 1e-4)\n    depth = kwargs.get('depth', 5)\n    width = kwargs.get('width', 256)\n    n_views = kwargs.get(\"n_views\", 4)\n    n_augs = kwargs.get('n_augs', 1)\n    clipavg = kwargs.get('clipavg', 'view')\n    device = kwargs.get('device', 'cuda')\n\n    # Initialize network and optimizer\n    net = NeuralHighlighter(\n        depth=depth,  # Number of hidden layers\n        width=width,  # Width of each layer\n        out_dim=2,  # Binary classification (highlight/no-highlight)\n        input_dim=3,  # 3D coordinates (x,y,z)\n        positional_encoding=False  # As recommended in the paper\n    ).to(device)\n    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n\n    # Set up the transforms\n    clip_transform, augment_transform = setup_clip_transforms()\n\n    # Training loop\n    for i in tqdm(range(num_iterations)):\n        optimizer.zero_grad()\n\n        # Predict highlight probabilities\n        pred_class = net(points)\n\n        # Create colors based on predictions\n        highlight_color = torch.tensor([204 / 255, 1.0, 0.0]).to(device)\n        base_color = torch.tensor([180 / 255, 180 / 255, 180 / 255]).to(device)\n\n        colors = pred_class[:, 0:1] * highlight_color + pred_class[:, 1:2] * base_color\n\n        # Create and render point cloud\n        point_cloud = renderer.create_point_cloud(points, colors)\n        rendered_images = renderer.render_all_views(point_cloud=point_cloud, n_views=n_views)\n        # Convert dictionary of images to tensor\n        rendered_tensor = []\n        for name, img in rendered_images.items():\n            rendered_tensor.append(img.to(device))\n        rendered_tensor = torch.stack(rendered_tensor)\n\n        #Convert rendered images to CLIP format\n        rendered_images = rendered_tensor.permute(0, 3, 1, 2)  # [B, H, W, C] -> [B, C, H, W]\n        #print(rendered_images.shape)\n\n        # Calculate CLIP loss\n        loss = clip_loss(\n            rendered_images=rendered_images,\n            encoded_text=encoded_text,\n            clip_transform=clip_transform,\n            augment_transform=augment_transform,\n            clip_model=clip_model,\n            n_augs=n_augs,\n            clipavg=clipavg\n        )\n        #print(\"Loss computation graph:\")\n        #print_grad_fn(loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % 100 == 0:\n            print(f\"Iteration {i}, Loss: {loss.item():.4f}\")\n            save_renders(log_dir, i, rendered_images)\n\n    return net\n\n\ndef main(input_path, object_name, highlight_region, **kwargs):\n    \"\"\"\n    Main function for 3D highlighting with configurable parameters.\n    \n    Args:\n        input_path: Path to input 3D file (mesh or point cloud)\n        object_name: Name of the object for the prompt\n        highlight_region: Region to highlight\n        **kwargs: Optional parameters with defaults:\n            n_views: Number of views to render (default: 5)\n            n_aug: Number of augmentations (default: 5) \n            clipavg: Method for CLIP averaging (default: \"view\")\n            network_depth: Depth of neural network (default: 5)\n            network_width: Width of neural layers (default: 256)\n            learning_rate: Learning rate for optimization (default: 1e-4)\n            num_iterations: Number of training iterations (default: 500)\n            num_points: Number of points to sample (default: 10000)\n            device: Device to run on (default: \"cuda\")\n            output_dir: Directory for outputs (default: \"./output\")\n    \"\"\"\n    # Extract parameters from kwargs with defaults\n    n_views = kwargs.get(\"n_views\", 4)\n    num_points = kwargs.get(\"num_points\", 10000)\n    device = kwargs.get(\"device\", \"cuda\")\n    output_dir = kwargs.get(\"output_dir\", \"./output\")\n    do_normalize = kwargs.get(\"do_normalize\", True) \n    \n    try:\n        # Create output directory if it doesn't exist\n        os.makedirs(output_dir, exist_ok=True)\n\n        # Load 3D data (either mesh or point cloud)\n        print(f\"Loading 3D data from {input_path}...\")\n        points, point_cloud = load_3d_data(input_path, num_points=num_points, device=device)\n        print(f\"Loaded {len(points)} points\")\n\n        # Setup CLIP model\n        print(\"Setting up CLIP model...\")\n        clip_model, preprocess, resolution = get_clip_model()\n\n        # Create and encode prompt\n        prompt = f\"A 3D render of a gray {object_name} with highlighted {highlight_region}\"\n        print(f\"Using prompt: {prompt}\")\n        text_features = encode_text(clip_model, prompt, device)\n\n        # Initialize renderer\n        print(\"Setting up renderer...\")\n        renderer = MultiViewPointCloudRenderer(\n            image_size=512,\n            base_dist=30,  # Your default view distance\n            base_elev=10,  # Your default elevation\n            base_azim=0,  # Your default azimuth\n            device=device\n        )\n\n        # Optimize point cloud highlighting\n        print(\"Starting optimization...\")\n        net = optimize_point_cloud(\n            points=points,\n            renderer=renderer,\n            clip_model=clip_model,\n            encoded_text=text_features,\n            log_dir=output_dir,\n            **kwargs\n        )\n\n        # Save results\n        print(\"Saving results...\")\n        save_results(\n            net=net,\n            points=points,\n            n_views=n_views,\n            prompt=prompt,\n            output_dir=output_dir,\n            renderer=renderer,\n            device=device\n        )\n\n        print(\"Processing complete!\")\n        return net, points\n\n    except Exception as e:\n        print(f\"Error in processing: {str(e)}\")\n        raise\n\n","metadata":{"id":"E0SBrmlBkwib","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:37:38.440674Z","iopub.execute_input":"2024-12-29T14:37:38.441009Z","iopub.status.idle":"2024-12-29T14:37:38.456613Z","shell.execute_reply.started":"2024-12-29T14:37:38.440981Z","shell.execute_reply":"2024-12-29T14:37:38.455726Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"main(\n    input_path=\"/kaggle/working/Affordance3DHighlighter/data/candle.obj\",\n    object_name=\"candle\",\n    highlight_region=\"head\",\n    n_views=4,\n    n_augs=1,\n    clipavg=\"view\",\n    network_depth=5,\n    network_width=256,\n    learning_rate=1e-4,\n    num_iterations=500,\n    num_points=100000,\n    device=\"cuda\",\n    output_dir=\"./output\"\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uD_gYzdOpy-t","outputId":"d0563f73-0957-4301-d62e-4937f39216e6","trusted":true,"execution":{"iopub.status.busy":"2024-12-29T14:51:45.103314Z","iopub.execute_input":"2024-12-29T14:51:45.103620Z","iopub.status.idle":"2024-12-29T14:55:01.180282Z","shell.execute_reply.started":"2024-12-29T14:51:45.103597Z","shell.execute_reply":"2024-12-29T14:55:01.179493Z"}},"outputs":[{"name":"stdout","text":"Loading 3D data from /kaggle/working/Affordance3DHighlighter/data/candle.obj...\nLoaded 100000 points\nSetting up CLIP model...\nUsing prompt: A 3D render of a gray candle with highlighted head\nSetting up renderer...\nStarting optimization...\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/500 [00:00<03:46,  2.21it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.3125\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 101/500 [00:38<02:37,  2.53it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.3384\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 201/500 [01:15<01:56,  2.56it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 200, Loss: -0.3213\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 301/500 [01:52<01:19,  2.50it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 300, Loss: -0.3279\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 401/500 [02:29<00:38,  2.54it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 400, Loss: -0.3447\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 500/500 [03:05<00:00,  2.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saving results...\nProcessing complete!\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"(NeuralHighlighter(\n   (mlp): ModuleList(\n     (0): Linear(in_features=3, out_features=256, bias=True)\n     (1): ReLU()\n     (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n     (3): Linear(in_features=256, out_features=256, bias=True)\n     (4): ReLU()\n     (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n     (6): Linear(in_features=256, out_features=256, bias=True)\n     (7): ReLU()\n     (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n     (9): Linear(in_features=256, out_features=256, bias=True)\n     (10): ReLU()\n     (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n     (12): Linear(in_features=256, out_features=256, bias=True)\n     (13): ReLU()\n     (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n     (15): Linear(in_features=256, out_features=256, bias=True)\n     (16): ReLU()\n     (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n     (18): Linear(in_features=256, out_features=2, bias=True)\n     (19): Softmax(dim=1)\n   )\n ),\n tensor([[ 0.0370, -0.3501,  0.3173],\n         [-0.1128,  0.1220, -0.1137],\n         [ 0.0968,  0.1463,  0.0266],\n         ...,\n         [ 0.0212,  0.0707,  0.1749],\n         [ 0.0366, -0.3441,  0.3553],\n         [-0.1221, -0.3514, -0.0248]], device='cuda:0'))"},"metadata":{}}],"execution_count":36}]}