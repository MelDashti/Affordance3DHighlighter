{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone --branch part2and3-mel https://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@github.com/amiralichangizi/Affordance3DHighlighter.git","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-30T21:47:19.876332Z","iopub.execute_input":"2024-12-30T21:47:19.876644Z","iopub.status.idle":"2024-12-30T21:47:20.914669Z","shell.execute_reply.started":"2024-12-30T21:47:19.876617Z","shell.execute_reply":"2024-12-30T21:47:20.913857Z"},"id":"2rqJobuCpQLi","outputId":"281b69ef-7d5c-40e7-e9d1-c343706616ea","trusted":true},"outputs":[{"name":"stdout","text":"Cloning into 'Affordance3DHighlighter'...\nremote: Enumerating objects: 190, done.\u001b[K\nremote: Counting objects: 100% (190/190), done.\u001b[K\nremote: Compressing objects: 100% (133/133), done.\u001b[K\nremote: Total 190 (delta 105), reused 135 (delta 54), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (190/190), 2.29 MiB | 6.79 MiB/s, done.\nResolving deltas: 100% (105/105), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\n\nos.chdir('/kaggle/working/Affordance3DHighlighter')","metadata":{"execution":{"iopub.status.busy":"2024-12-30T21:47:22.950814Z","iopub.execute_input":"2024-12-30T21:47:22.951109Z","iopub.status.idle":"2024-12-30T21:47:22.954797Z","shell.execute_reply.started":"2024-12-30T21:47:22.951087Z","shell.execute_reply":"2024-12-30T21:47:22.954009Z"},"id":"fhLYzi952EEA","trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"!pip install gdown\n!gdown --id 1siZtGusB1LfQVapTvNOiYi8aeKKAgcDF\n!unzip full-shape.zip -d /kaggle/working/Affordance3DHighlighter/data/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:47:24.596644Z","iopub.execute_input":"2024-12-30T21:47:24.596938Z","iopub.status.idle":"2024-12-30T21:47:55.415488Z","shell.execute_reply.started":"2024-12-30T21:47:24.596916Z","shell.execute_reply":"2024-12-30T21:47:55.414350Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\nRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\nRequirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\nRequirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1siZtGusB1LfQVapTvNOiYi8aeKKAgcDF\nFrom (redirected): https://drive.google.com/uc?id=1siZtGusB1LfQVapTvNOiYi8aeKKAgcDF&confirm=t&uuid=6dc2e5e3-a1c7-4eee-9ccb-31b8a704d7ac\nTo: /kaggle/working/Affordance3DHighlighter/full-shape.zip\n100%|█████████████████████████████████████████| 558M/558M [00:03<00:00, 167MB/s]\nArchive:  full-shape.zip\n  inflating: /kaggle/working/Affordance3DHighlighter/data/full_shape_train_data.pkl  \n  inflating: /kaggle/working/Affordance3DHighlighter/data/full_shape_val_data.pkl  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pickle\n\n# Load training data\nwith open('/kaggle/working/Affordance3DHighlighter/data/full_shape_train_data.pkl', 'rb') as train_file:\n    train_data = pickle.load(train_file)\n# Inspect the contents\nprint(f\"Training Data Type: {type(train_data)}\")\nprint(f\"Training Data Example: {train_data[:1]}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:48:17.912508Z","iopub.execute_input":"2024-12-30T21:48:17.912955Z","iopub.status.idle":"2024-12-30T21:48:22.183883Z","shell.execute_reply.started":"2024-12-30T21:48:17.912922Z","shell.execute_reply":"2024-12-30T21:48:22.182975Z"}},"outputs":[{"name":"stdout","text":"Training Data Type: <class 'list'>\nTraining Data Example: [{'shape_id': '63e0b01c60c1a0edfafd17eed9590afe', 'semantic class': 'Door', 'affordance': ['grasp', 'contain', 'lift', 'openable', 'layable', 'sittable', 'support', 'wrap_grasp', 'pourable', 'move', 'displaY', 'pushable', 'pull', 'listen', 'wear', 'press', 'cut', 'stab'], 'full_shape': {'coordinate': array([[ 0.15929998, -0.7428185 , -0.00485236],\n       [-0.22462437,  0.972573  ,  0.00416868],\n       [ 0.221295  ,  0.1727677 ,  0.00374921],\n       ...,\n       [-0.10196283,  0.636612  , -0.01006717],\n       [ 0.0958824 , -0.9201699 ,  0.00974288],\n       [-0.16395783,  0.60726637,  0.00812608]], dtype=float32), 'label': {'grasp': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'contain': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'lift': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'openable': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'layable': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'sittable': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'support': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'wrap_grasp': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'pourable': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'move': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'displaY': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'pushable': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'pull': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'listen': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'wear': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'press': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'cut': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32), 'stab': array([[0.],\n       [0.],\n       [0.],\n       ...,\n       [0.],\n       [0.],\n       [0.]], dtype=float32)}}}]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"!pip install git+https://github.com/openai/CLIP.git\n!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-30T21:48:29.818574Z","iopub.execute_input":"2024-12-30T21:48:29.818933Z","iopub.status.idle":"2024-12-30T21:48:47.190070Z","shell.execute_reply.started":"2024-12-30T21:48:29.818905Z","shell.execute_reply":"2024-12-30T21:48:47.188963Z"},"id":"d8vCbctxbPP4","outputId":"55a100ed-7b85-4630-9e3f-e3ce98c37fff","trusted":true},"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-kzdagwip\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-kzdagwip\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting ftfy (from clip==1.0)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (24.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2024.9.11)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (4.66.5)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (2.4.1+cu121)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from clip==1.0) (0.19.1+cu121)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->clip==1.0) (2024.6.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->clip==1.0) (10.4.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->clip==1.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: clip\n  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=814d9ca97ae0ad7dbf1d70c3c4dd94e3e0c5c759c4872ddc450878d521fe1158\n  Stored in directory: /tmp/pip-ephem-wheel-cache-grhr28yj/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\nSuccessfully built clip\nInstalling collected packages: ftfy, clip\nSuccessfully installed clip-1.0 ftfy-6.3.1\nLooking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html\nCollecting kaolin==0.17.0\n  Downloading https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121/kaolin-0.17.0-cp310-cp310-linux_x86_64.whl (5.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting ipycanvas (from kaolin==0.17.0)\n  Downloading ipycanvas-0.13.3-py2.py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: ipyevents in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.0.2)\nCollecting jupyter-client<8 (from kaolin==0.17.0)\n  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.2.5)\nRequirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (6.3.3)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (0.2.2)\nCollecting usd-core (from kaolin==0.17.0)\n  Downloading usd_core-24.11-cp310-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.26.4)\nRequirement already satisfied: pybind11 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (2.13.6)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (10.4.0)\nRequirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (4.66.5)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.13.1)\nRequirement already satisfied: pygltflib in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (1.16.3)\nCollecting warp-lang (from kaolin==0.17.0)\n  Downloading warp_lang-1.5.0-py3-none-manylinux2014_x86_64.whl.metadata (25 kB)\nRequirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from kaolin==0.17.0) (7.34.0)\nRequirement already satisfied: traitlets>=4 in /usr/local/lib/python3.10/dist-packages (from comm>=0.1.3->kaolin==0.17.0) (5.7.1)\nRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (0.4)\nRequirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.7.2)\nRequirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (1.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (2.8.2)\nRequirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8->kaolin==0.17.0) (24.0.1)\nRequirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.0.4)\nRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (2.2.0)\nRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask->kaolin==0.17.0) (8.1.7)\nRequirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.10/dist-packages (from ipycanvas->kaolin==0.17.0) (8.1.5)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (71.0.4)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (3.0.47)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->kaolin==0.17.0) (4.9.0)\nRequirement already satisfied: dataclasses-json>=0.0.25 in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.17.0) (0.6.7)\nRequirement already satisfied: deprecated in /usr/local/lib/python3.10/dist-packages (from pygltflib->kaolin==0.17.0) (1.2.15)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (3.23.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (0.9.0)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.0.13)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->kaolin==0.17.0) (0.8.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask->kaolin==0.17.0) (2.1.5)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.9.2->jupyter-client<8->kaolin==0.17.0) (4.3.6)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->kaolin==0.17.0) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kaolin==0.17.0) (0.2.13)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->jupyter-client<8->kaolin==0.17.0) (1.16.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated->pygltflib->kaolin==0.17.0) (1.16.0)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (24.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (1.0.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (4.12.2)\nDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading ipycanvas-0.13.3-py2.py3-none-any.whl (125 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading usd_core-24.11-cp310-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.4/25.4 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading warp_lang-1.5.0-py3-none-manylinux2014_x86_64.whl (84.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: warp-lang, usd-core, jupyter-client, ipycanvas, kaolin\n  Attempting uninstall: jupyter-client\n    Found existing installation: jupyter_client 8.6.3\n    Uninstalling jupyter_client-8.6.3:\n      Successfully uninstalled jupyter_client-8.6.3\nSuccessfully installed ipycanvas-0.13.3 jupyter-client-7.4.9 kaolin-0.17.0 usd-core-24.11 warp-lang-1.5.0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nimport sys\nimport torch\n\nneed_pytorch3d = False\ntry:\n    import pytorch3d\nexcept ModuleNotFoundError:\n    need_pytorch3d = True\nif need_pytorch3d:\n    pyt_version_str = torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n    version_str = \"\".join([\n        f\"py3{sys.version_info.minor}_cu\",\n        torch.version.cuda.replace(\".\", \"\"),\n        f\"_pyt{pyt_version_str}\"\n    ])\n    !pip install iopath\n    if sys.platform.startswith(\"linux\"):\n        print(\"Trying to install wheel for PyTorch3D\")\n        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n        pip_list = !pip freeze\n        need_pytorch3d = not any(i.startswith(\"pytorch3d==\") for i in pip_list)\n    if need_pytorch3d:\n        print(f\"failed to find/install wheel for {version_str}\")\nif need_pytorch3d:\n    print(\"Installing PyTorch3D from source\")\n    !pip install ninja\n    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'","metadata":{"ExecuteTime":{"end_time":"2024-12-26T14:58:53.585274Z","start_time":"2024-12-26T14:58:48.836644Z"},"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-30T21:48:47.191517Z","iopub.execute_input":"2024-12-30T21:48:47.191837Z","iopub.status.idle":"2024-12-30T21:49:00.588424Z","shell.execute_reply.started":"2024-12-30T21:48:47.191814Z","shell.execute_reply":"2024-12-30T21:49:00.587504Z"},"id":"sRNWfRMnIzuJ","outputId":"39ed1f77-3f8e-499d-eb2b-8aecadf7c335","trusted":true},"outputs":[{"name":"stdout","text":"Collecting iopath\n  Downloading iopath-0.1.10.tar.gz (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath) (4.66.5)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from iopath) (4.12.2)\nCollecting portalocker (from iopath)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: iopath\n  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31529 sha256=f9b673d4d10af5398e758f8b8989511c19b377eddd066c897491e97f0796c81d\n  Stored in directory: /root/.cache/pip/wheels/9a/a3/b6/ac0fcd1b4ed5cfeb3db92e6a0e476cfd48ed0df92b91080c1d\nSuccessfully built iopath\nInstalling collected packages: portalocker, iopath\nSuccessfully installed iopath-0.1.10 portalocker-3.0.0\nTrying to install wheel for PyTorch3D\nLooking in links: https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py310_cu121_pyt241/download.html\nCollecting pytorch3d\n  Downloading https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/py310_cu121_pyt241/pytorch3d-0.7.8-cp310-cp310-linux_x86_64.whl (20.5 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from pytorch3d) (0.1.10)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d) (4.66.5)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d) (4.12.2)\nRequirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->pytorch3d) (3.0.0)\nInstalling collected packages: pytorch3d\nSuccessfully installed pytorch3d-0.7.8\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"!pip install open3d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-30T21:49:11.299580Z","iopub.execute_input":"2024-12-30T21:49:11.300233Z","iopub.status.idle":"2024-12-30T21:49:30.906190Z","shell.execute_reply.started":"2024-12-30T21:49:11.300205Z","shell.execute_reply":"2024-12-30T21:49:30.905335Z"},"id":"zT9LfpcRXDHy","outputId":"527d847c-60da-4e72-c096-81cbf9671f92","trusted":true},"outputs":[{"name":"stdout","text":"Collecting open3d\n  Downloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl.metadata (4.2 kB)\nRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.26.4)\nCollecting dash>=2.6.0 (from open3d)\n  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: werkzeug>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.0.4)\nRequirement already satisfied: nbformat>=5.7.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (5.10.4)\nCollecting configargparse (from open3d)\n  Downloading ConfigArgParse-1.7-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: ipywidgets>=8.0.4 in /usr/local/lib/python3.10/dist-packages (from open3d) (8.1.5)\nCollecting addict (from open3d)\n  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\nRequirement already satisfied: pillow>=9.3.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (10.4.0)\nRequirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.10/dist-packages (from open3d) (3.7.1)\nRequirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/dist-packages (from open3d) (2.1.4)\nRequirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from open3d) (6.0.2)\nRequirement already satisfied: scikit-learn>=0.21 in /usr/local/lib/python3.10/dist-packages (from open3d) (1.2.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from open3d) (4.66.5)\nCollecting pyquaternion (from open3d)\n  Downloading pyquaternion-0.9.9-py3-none-any.whl.metadata (1.4 kB)\nRequirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.2.5)\nRequirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (5.24.1)\nCollecting dash-html-components==2.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\nCollecting dash-core-components==2.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\nCollecting dash-table==5.0.0 (from dash>=2.6.0->open3d)\n  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (8.5.0)\nRequirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (4.12.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (2.32.3)\nCollecting retrying (from dash>=2.6.0->open3d)\n  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (1.6.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from dash>=2.6.0->open3d) (71.0.4)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (0.2.2)\nRequirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (7.34.0)\nRequirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (5.7.1)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=8.0.4->open3d) (3.0.13)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (24.1)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3->open3d) (2.8.2)\nRequirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (2.20.0)\nRequirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (4.23.0)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.0->open3d) (5.7.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0->open3d) (2024.1)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21->open3d) (3.5.0)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=2.2.3->open3d) (2.1.5)\nRequirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (3.1.4)\nRequirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (2.2.0)\nRequirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3.1,>=1.0.4->dash>=2.6.0->open3d) (8.1.7)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.47)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.18.0)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (4.9.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (24.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.20.0)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.3.6)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (9.0.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3->open3d) (1.16.0)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.20.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->dash>=2.6.0->open3d) (2024.8.30)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.13)\nDownloading open3d-0.18.0-cp310-cp310-manylinux_2_27_x86_64.whl (399.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m399.7/399.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\nDownloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\nDownloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\nDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\nDownloading ConfigArgParse-1.7-py3-none-any.whl (25 kB)\nDownloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\nDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\nInstalling collected packages: dash-table, dash-html-components, dash-core-components, addict, retrying, pyquaternion, configargparse, dash, open3d\nSuccessfully installed addict-2.4.0 configargparse-1.7 dash-2.18.2 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 open3d-0.18.0 pyquaternion-0.9.9 retrying-1.3.4\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"!mkdir -p data/PittsburghBridge\n!wget -P data/PittsburghBridge https://dl.fbaipublicfiles.com/pytorch3d/data/PittsburghBridge/pointcloud.npz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.status.busy":"2024-12-30T21:49:30.907664Z","iopub.execute_input":"2024-12-30T21:49:30.907987Z","iopub.status.idle":"2024-12-30T21:49:31.604721Z","shell.execute_reply.started":"2024-12-30T21:49:30.907957Z","shell.execute_reply":"2024-12-30T21:49:31.603879Z"},"id":"FTk44DGYYIBS","outputId":"864b8bfd-a638-4f09-f520-d3f0fb75389c","trusted":true},"outputs":[{"name":"stdout","text":"--2024-12-30 21:49:31--  https://dl.fbaipublicfiles.com/pytorch3d/data/PittsburghBridge/pointcloud.npz\nResolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.244.202.103, 18.244.202.73, 18.244.202.25, ...\nConnecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.244.202.103|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 5701352 (5.4M) [application/zip]\nSaving to: ‘data/PittsburghBridge/pointcloud.npz’\n\npointcloud.npz      100%[===================>]   5.44M  26.5MB/s    in 0.2s    \n\n2024-12-30 21:49:31 (26.5 MB/s) - ‘data/PittsburghBridge/pointcloud.npz’ saved [5701352/5701352]\n\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nfrom src.mesh import Mesh\nfrom pytorch3d.structures import Pointclouds\n\nfrom src.convertor import obj_to_pointcloud\n\n\ndef bounding_sphere_normalize(points: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    points: (N,3) tensor of point coords\n    Return normalized points in a unit sphere centered at origin.\n    \"\"\"\n    center = points.mean(dim=0, keepdim=True)\n    max_dist = (points - center).norm(p=2, dim=1).max()\n    points_normed = (points - center) / max_dist\n    return points_normed\n\n\ndef load_3d_data(file_path, num_points=10000, device=\"cuda\", do_normalize=True):\n    \"\"\"\n    Loads 3D data as PyTorch3D Pointclouds from either NPZ point cloud or OBJ mesh.\n\n    Args:\n        file_path: Path to either .npz point cloud or .obj mesh file\n        num_points: Number of points to sample if loading from mesh\n        device: Device to load data on\n\n    Returns:\n        Pointclouds object containing points and features\n    \"\"\"\n    file_ext = file_path.split('.')[-1].lower()\n\n    if file_ext == 'npz':\n        # Load NPZ point cloud directly like in the example\n        pointcloud = np.load(file_path)\n        verts = torch.Tensor(pointcloud['verts']).to(device)\n        rgb = torch.Tensor(pointcloud['rgb']).to(device)\n\n        print(\"lenght of the data\")\n        print(len(verts))\n\n        # Subsample if needed\n        if len(verts) > num_points:\n            idx = torch.randperm(len(verts))[:num_points]\n            verts = verts[idx]\n            rgb = rgb[idx]\n\n        if do_normalize:\n            verts = bounding_sphere_normalize(verts)\n\n        # Return both the points tensor and the Pointclouds object\n        point_cloud = Pointclouds(points=[verts], features=[rgb])\n        return verts, point_cloud  # Return both\n\n    elif file_ext == 'obj':\n        # Load and convert your OBJ file\n        points, point_cloud = obj_to_pointcloud(\n            file_path,\n            num_points=num_points,  # Adjust this number as needed\n            device=\"cuda\"  # Use \"cpu\" if you don't have a GPU\n        )\n        if do_normalize:\n            points = bounding_sphere_normalize(points)\n            # here we update the point cloud too\n            rgb = point_cloud.features_packed() # shape [N,3]\n            point_cloud = Pointclouds(points = [points], features = [rgb])\n        return points, point_cloud\n        # # Load mesh and sample points\n        # mesh = Mesh(file_path)\n        # vertices = mesh.vertices\n\n        # # Sample random points\n        # idx = torch.randperm(vertices.shape[0])[:num_points]\n        # points = vertices[idx].to(device)\n\n        # # Initialize with gray color\n        # colors = torch.ones_like(points) * 0.7\n\n        # return Pointclouds(points=[points], features=[colors])\n\n    else:\n        raise ValueError(f\"Unsupported file format: {file_ext}. Only .npz and .obj are supported.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-30T21:49:34.469950Z","iopub.execute_input":"2024-12-30T21:49:34.470249Z","iopub.status.idle":"2024-12-30T21:49:37.214157Z","shell.execute_reply.started":"2024-12-30T21:49:34.470225Z","shell.execute_reply":"2024-12-30T21:49:37.213271Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Warp 1.5.0 initialized:\n   CUDA Toolkit 12.6, Driver 12.6\n   Devices:\n     \"cpu\"      : \"x86_64\"\n     \"cuda:0\"   : \"Tesla P100-PCIE-16GB\" (16 GiB, sm_60, mempool enabled)\n   Kernel cache:\n     /root/.cache/warp/1.5.0\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def print_grad_fn(tensor, depth=0):\n    \"\"\"Recursively print the gradient function graph\"\"\"\n    if tensor.grad_fn is None:\n        print(\"  \" * depth + \"None (leaf tensor)\")\n        return\n\n    print(\"  \" * depth + str(tensor.grad_fn))\n    for fn in tensor.grad_fn.next_functions:\n        if fn[0] is not None:\n            print(\"  \" * (depth + 1) + str(fn[0]))","metadata":{"execution":{"iopub.execute_input":"2024-12-29T14:25:41.677365Z","iopub.status.busy":"2024-12-29T14:25:41.677027Z","iopub.status.idle":"2024-12-29T14:25:41.682294Z","shell.execute_reply":"2024-12-29T14:25:41.681359Z","shell.execute_reply.started":"2024-12-29T14:25:41.677336Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"\nfrom src.render.cloud_point_renderer import MultiViewPointCloudRenderer\nfrom src.save_results import save_renders, save_results\nfrom src.neural_highlighter import NeuralHighlighter\nfrom src.Clip.loss_function import clip_loss\nfrom src.Clip.clip_model import get_clip_model, encode_text, setup_clip_transforms\n\nimport torch\nimport numpy as np\nimport random\nfrom tqdm import tqdm\n\n# Constrain most sources of randomness\n# (some torch backwards functions within CLIP are non-determinstic)\n# Set a consistent seed for reproducibility\nseed = 0  # You can use any integer value\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n\n\ndef optimize_point_cloud(points, clip_model, renderer, encoded_text, log_dir: str, **kwargs):\n    num_iterations = kwargs.get('num_iterations', 1000)\n    learning_rate = kwargs.get('learning_rate', 1e-4)\n    depth = kwargs.get('depth', 5)\n    width = kwargs.get('network_width', 256)\n    n_views = kwargs.get(\"n_views\", 4)\n    n_augs = kwargs.get('n_augs', 1)\n    clipavg = kwargs.get('clipavg', 'view')\n    device = kwargs.get('device', 'cuda')\n\n    # Initialize network and optimizer\n    net = NeuralHighlighter(\n        depth=depth,  # Number of hidden layers\n        width=width,  # Width of each layer\n        out_dim=2,  # Binary classification (highlight/no-highlight)\n        input_dim=3,  # 3D coordinates (x,y,z)\n        positional_encoding=False  # As recommended in the paper\n    ).to(device)\n    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n\n    # Set up the transforms\n    clip_transform, augment_transform = setup_clip_transforms()\n\n    # Training loop\n    for i in tqdm(range(num_iterations)):\n        optimizer.zero_grad()\n\n        # Predict highlight probabilities\n        pred_class = net(points)\n\n        # Create colors based on predictions\n        highlight_color = torch.tensor([204 / 255, 1.0, 0.0]).to(device)\n        base_color = torch.tensor([180 / 255, 180 / 255, 180 / 255]).to(device)\n\n        colors = pred_class[:, 0:1] * highlight_color + pred_class[:, 1:2] * base_color\n\n        # Create and render point cloud\n        point_cloud = renderer.create_point_cloud(points, colors)\n        rendered_images = renderer.render_all_views(point_cloud=point_cloud, n_views=n_views)\n        # Convert dictionary of images to tensor\n        rendered_tensor = []\n        for name, img in rendered_images.items():\n            rendered_tensor.append(img.to(device))\n        rendered_tensor = torch.stack(rendered_tensor)\n\n        #Convert rendered images to CLIP format\n        rendered_images = rendered_tensor.permute(0, 3, 1, 2)  # [B, H, W, C] -> [B, C, H, W]\n        #print(rendered_images.shape)\n\n        # Calculate CLIP loss\n        loss = clip_loss(\n            rendered_images=rendered_images,\n            encoded_text=encoded_text,\n            clip_transform=clip_transform,\n            augment_transform=augment_transform,\n            clip_model=clip_model,\n            n_augs=n_augs,\n            clipavg=clipavg\n        )\n        #print(\"Loss computation graph:\")\n        #print_grad_fn(loss)\n        loss.backward()\n        optimizer.step()\n\n        if i % 100 == 0:\n            print(f\"Iteration {i}, Loss: {loss.item():.4f}\")\n            save_renders(log_dir, i, rendered_images)\n\n    return net\n\n\ndef main(input_path, object_name, highlight_region, **kwargs):\n    \"\"\"\n    Main function for 3D highlighting with configurable parameters.\n    \n    Args:\n        input_path: Path to input 3D file (mesh or point cloud)\n        object_name: Name of the object for the prompt\n        highlight_region: Region to highlight\n        **kwargs: Optional parameters with defaults:\n            n_views: Number of views to render (default: 5)\n            n_aug: Number of augmentations (default: 5) \n            clipavg: Method for CLIP averaging (default: \"view\")\n            network_depth: Depth of neural network (default: 5)\n            network_width: Width of neural layers (default: 256)\n            learning_rate: Learning rate for optimization (default: 1e-4)\n            num_iterations: Number of training iterations (default: 500)\n            num_points: Number of points to sample (default: 10000)\n            device: Device to run on (default: \"cuda\")\n            output_dir: Directory for outputs (default: \"./output\")\n    \"\"\"\n    # Extract parameters from kwargs with defaults\n    n_views = kwargs.get(\"n_views\", 4)\n    num_points = kwargs.get(\"num_points\", 10000)\n    device = kwargs.get(\"device\", \"cuda\")\n    output_dir = kwargs.get(\"output_dir\", \"./output\")\n    do_normalize = kwargs.get(\"do_normalize\", True) \n    \n    try:\n        # Create output directory if it doesn't exist\n        os.makedirs(output_dir, exist_ok=True)\n\n        # Load 3D data (either mesh or point cloud)\n        print(f\"Loading 3D data from {input_path}...\")\n        points, point_cloud = load_3d_data(input_path, num_points=num_points, device=device)\n        print(f\"Loaded {len(points)} points\")\n\n        # Setup CLIP model\n        print(\"Setting up CLIP model...\")\n        clip_model, preprocess, resolution = get_clip_model()\n\n        # Create and encode prompt\n        prompt = f\"A 3D render of a gray {object_name} with highlighted {highlight_region}\"\n        print(f\"Using prompt: {prompt}\")\n        text_features = encode_text(clip_model, prompt, device)\n\n        # Initialize renderer\n        print(\"Setting up renderer...\")\n        renderer = MultiViewPointCloudRenderer(\n            image_size=512,\n            base_dist=30,  # Your default view distance\n            base_elev=10,  # Your default elevation\n            base_azim=0,  # Your default azimuth\n            device=device\n        )\n\n        # Optimize point cloud highlighting\n        print(\"Starting optimization...\")\n        net = optimize_point_cloud(\n            points=points,\n            renderer=renderer,\n            clip_model=clip_model,\n            encoded_text=text_features,\n            log_dir=output_dir,\n            **kwargs\n        )\n\n        # Save results\n        print(\"Saving results...\")\n        save_results(\n            net=net,\n            points=points,\n            n_views=n_views,\n            prompt=prompt,\n            output_dir=output_dir,\n            renderer=renderer,\n            device=device\n        )\n\n        print(\"Processing complete!\")\n        return net, points\n\n    except Exception as e:\n        print(f\"Error in processing: {str(e)}\")\n        raise\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-30T21:50:01.351615Z","iopub.execute_input":"2024-12-30T21:50:01.352027Z","iopub.status.idle":"2024-12-30T21:50:03.640779Z","shell.execute_reply.started":"2024-12-30T21:50:01.352002Z","shell.execute_reply":"2024-12-30T21:50:03.639829Z"},"id":"E0SBrmlBkwib","trusted":true},"outputs":[{"name":"stdout","text":"Jupyter environment detected. Enabling Open3D WebVisualizer.\n[Open3D INFO] WebRTC GUI backend enabled.\n[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"main(\n    input_path=\"/kaggle/working/Affordance3DHighlighter/data/candle.obj\",\n    object_name=\"candle\",\n    highlight_region=\"head\",\n    n_views=4,\n    n_augs=1,\n    clipavg=\"view\",\n    network_depth=5,\n    network_width=256,\n    learning_rate=1e-4,\n    num_iterations=500,\n    num_points=100000,\n    device=\"cuda\",\n    output_dir=\"./output\"\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"execution":{"iopub.execute_input":"2024-12-29T14:51:45.103620Z","iopub.status.busy":"2024-12-29T14:51:45.103314Z","iopub.status.idle":"2024-12-29T14:55:01.180282Z","shell.execute_reply":"2024-12-29T14:55:01.179493Z","shell.execute_reply.started":"2024-12-29T14:51:45.103597Z"},"id":"uD_gYzdOpy-t","outputId":"d0563f73-0957-4301-d62e-4937f39216e6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Evaluation for part 3 ","metadata":{}},{"cell_type":"markdown","source":"Main for the other dataset","metadata":{}},{"cell_type":"code","source":"from src.evaluation_fullshapev2 import evaluate_single_object, visualize_single_object\nfrom src.data_loader_fullshape import FullShapeDataset, create_dataset_splits\nfrom src.render.cloud_point_renderer import MultiViewPointCloudRenderer\nfrom src.neural_highlighter import NeuralHighlighter\nfrom src.Clip.clip_model import get_clip_model, encode_text\n\ndef main(data_entry, net, clip_model, renderer, device=\"cuda\", **kwargs):\n    \"\"\"\n    Main function to process a single dataset entry.\n    Args:\n        data_entry (dict): Single object data from the dataset.\n        net: Neural highlighting model.\n        clip_model: CLIP model.\n        renderer: Renderer for visualization.\n        device (str): Device for computation.\n        **kwargs: Additional parameters for optimization.\n    \"\"\"\n    try:\n        # Extract information from the dataset entry\n        points = data_entry[\"coords\"]  # Nx3 point cloud\n        shape_id = data_entry[\"shape_id\"]\n        shape_class = data_entry[\"shape_class\"]\n        highlight_region = data_entry[\"affordances\"][0]  # Use the first affordance for testing\n        \n        # Generate prompt\n        prompt = f\"A 3D render of a gray {shape_class} with highlighted {highlight_region}\"\n        print(f\"Using prompt: {prompt}\")\n        text_features = encode_text(clip_model, prompt, device)\n\n        # Optimize point cloud highlighting\n        print(\"Starting optimization...\")\n        net = optimize_point_cloud(\n            points=points,\n            renderer=renderer,\n            clip_model=clip_model,\n            encoded_text=text_features,\n            log_dir=kwargs.get(\"output_dir\", \"./output\"),\n            **kwargs\n        )\n\n        # Save results\n        print(\"Saving results...\")\n        save_results(\n            net=net,\n            points=points,\n            n_views=kwargs.get(\"n_views\", 4),\n            prompt=prompt,\n            output_dir=kwargs.get(\"output_dir\", \"./output\"),\n            renderer=renderer,\n            device=device\n        )\n\n        print(f\"Processing complete for shape_id: {shape_id}\")\n        \n        # Optional visualization\n        if kwargs.get(\"visualize\", True):\n            visualize_single_object(data_entry, net, clip_model, device=device, out_dir=kwargs.get(\"output_dir\", \"./output\"))\n\n        return net, points\n\n    except Exception as e:\n        print(f\"Error in processing shape_id {data_entry['shape_id']}: {str(e)}\")\n        raise\n\n# Loading the dataset\n# We only use the val_data and test_data for part 3. 10 percent of train set is validation set \n# and 5 percent of train set is test set.\n# also when loading the dataset (better seen in Dataset Loader), specific classes and affordance labels \n# have been filtered as per the req in part 3. \ndataset = FullShapeDataset(\"/kaggle/working/Affordance3DHighlighter/data/full_shape_train_data.pkl\", device=\"cuda\")\ntrain_data, val_data, test_data = create_dataset_splits(dataset, val_ratio=0.1, test_ratio=0.05)\n\n# Ensure test set is not empty\nif len(test_data) == 0:\n    raise ValueError(\"Test dataset is empty. Check your dataset and split ratios.\")\n\n# Select a single object from the test set\ndata_index = 0  # You can adjust this to test different objects\ndata_entry = test_data[data_index]\n\n# Setup CLIP and Renderer\nclip_model, preprocess, resolution = get_clip_model()\nrenderer = MultiViewPointCloudRenderer(image_size=512, base_dist=30, base_elev=10, device=\"cuda\")\n\n# Setup Neural Highlighter\nnet = NeuralHighlighter(depth=5, width=256, out_dim=2, input_dim=3).to(\"cuda\")\n\n# Run the main function for a single object\nmain(\n    data_entry=data_entry,\n    net=net,\n    clip_model=clip_model,\n    renderer=renderer,\n    device=\"cuda\",\n    num_iterations=500,\n    learning_rate=1e-4,\n    output_dir=\"./results\",\n    visualize=True\n)\n\n# Evaluate affordances for the object\nresults = evaluate_single_object(data_entry, net, clip_model, device=\"cuda\")\nprint(\"Evaluation Results:\", results)\n\n# Visualize predictions\nvisualize_single_object(data_entry, net, clip_model, device=\"cuda\", out_dir=\"./results\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:50:30.634603Z","iopub.execute_input":"2024-12-30T21:50:30.634928Z","iopub.status.idle":"2024-12-30T21:53:55.845444Z","shell.execute_reply.started":"2024-12-30T21:50:30.634904Z","shell.execute_reply":"2024-12-30T21:53:55.844764Z"}},"outputs":[{"name":"stderr","text":"100%|███████████████████████████████████████| 890M/890M [00:09<00:00, 95.7MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nUsing prompt: A 3D render of a gray Door with highlighted openable\nStarting optimization...\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/500 [00:01<10:03,  1.21s/it]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2380\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 101/500 [00:36<02:23,  2.78it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2036\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 201/500 [01:11<01:47,  2.79it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 200, Loss: -0.2825\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 301/500 [01:46<01:11,  2.79it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 300, Loss: -0.2216\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 401/500 [02:21<00:35,  2.78it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 400, Loss: -0.2391\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 500/500 [02:56<00:00,  2.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Saving results...\nProcessing complete for shape_id: 5b04e0f9bfb4e98aa965a3d6737ac4\nEvaluation Results: [{'shape_id': '5b04e0f9bfb4e98aa965a3d6737ac4', 'shape_class': 'Door', 'affordance': 'openable', 'IoU': 0.018284106627106667, 'prompt': 'A 3D render of a gray Door with highlighted openable region'}, {'shape_id': '5b04e0f9bfb4e98aa965a3d6737ac4', 'shape_class': 'Door', 'affordance': 'pushable', 'IoU': 0.01825842633843422, 'prompt': 'A 3D render of a gray Door with highlighted pushable region'}, {'shape_id': '5b04e0f9bfb4e98aa965a3d6737ac4', 'shape_class': 'Door', 'affordance': 'pull', 'IoU': 0.018284106627106667, 'prompt': 'A 3D render of a gray Door with highlighted pull region'}]\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"### New strategy for evaluation\nHyperparam + Strategy Tuning, Then Test Evaluation","metadata":{}},{"cell_type":"code","source":"from src.evaluation_fullshape import (\n    compute_mIoU,  # needed for final checks\n    evaluate_single_object,\n    grid_search_validation,   # We'll define a simple approach\n    evaluate_dataset\n)\n\n# Here we define a short list of strategies and thresholds. \nstrategies_list = [\"basic\", \"functional\", \"descriptive\", \"action\"]\nthresholds_list = [0.3, 0.5, 0.7]\n\nclip_model2, _, _= get_clip_model()\nrenderer2 = MultiViewPointCloudRenderer(\n    image_size=512, base_dist=30, base_elev=10, device=\"cuda\"\n)\nnet2 = NeuralHighlighter(depth=5, width=256, out_dim=2, input_dim=3).to(\"cuda\")\n\n# Here we pick 4 objects from val\nval_size = len(val_data)\nnum_val_objects = min(3, val_size)\nval_indices = list(range(num_val_objects))\n\nbest_strat = None\nbest_th = None \nbest_iou = 1.0 \n\n# For each of these 4 val objects, we train from scratch. Then measure how well each (strat, threshold)\n# for now, perform across all affordances of that shape. \n# Then we will average the IoU across these 4 shapes to pick the best approach. \nval_results = [] # Here we store shape level IoU so we can compute the average. \n\nfor strategy in strategies_list:\n    for threshold in thresholds_list:\n        # here we will accumulate the iou across the 4 shapes\n        sum_iou = 0.0\n        count = 0\n        for idx in val_indices:\n            val_entry = val_data[idx]\n            # now we train the network for the shape\n            shape_net = NeuralHighlighter(depth = 5, width = 256, out_dim = 2, input_dim=3).cuda()\n            shape_coords = val_entry[\"coords\"]\n            shape_class = val_entry[\"shape_class\"]\n            # Here we pick the first affordance for the main prompt\n            aff = val_entry[\"affordances\"][0]\n            prompt = f\"A 3D render of a gray {shape_class} with highlighted {aff}\"\n\n            # short training \n            txt_feats = encode_text(clip_model2, prompt, device = \"cuda\")\n            shape_renderer = MultiViewPointCloudRenderer(image_size = 256, base_dist=20, base_elev=10, device=\"cuda\")\n            shape_net=optimize_point_cloud(\n                points=shape_coords,\n                clip_model=clip_model2,\n                renderer=shape_renderer,\n                encoded_text=txt_feats,\n                log_dir=\"./val_tmp\",\n                num_iterations=200,\n                device=\"cuda\",\n                n_views=2\n            )\n\n            # measure IoU across all affs in that shape with (strategy, threshold)\n            aff_list = val_entry[\"affordances\"]\n            shape_sum = 0.0\n            c2 = 0\n            with torch.no_grad():\n                pred2 = shape_net(shape_coords)\n                highlight_prob2 = pred2[:, 0]\n            for a2 in aff_list:\n                gt_bin=(val_entry[\"labels_dict\"][a2]>0.5).long()\n                # apply threshold\n                bin_pred=(highlight_prob2>=threshold).long()\n                iou_val=compute_mIoU(bin_pred, gt_bin)\n                shape_sum+=iou_val\n                c2+=1\n\n            shape_mean=shape_sum/c2 if c2>0 else 0.0\n            sum_iou+=shape_mean\n            count+=1\n            \n        avg_iou= sum_iou/count if count>0 else 0.0\n        val_results.append((strategy,threshold,avg_iou))\n        if avg_iou>best_iou:\n            best_iou=avg_iou\n            best_strat=strategy\n            best_th=threshold\n\nprint(f\"[Val Done] best strategy={best_strat}, threshold={best_th}, meanIoU={best_iou:.3f}\")\n\n\n# Now with the best hyperparameters , strategy and threshold achieved we check the test set. \n# Now test with best\ntest_count= 3\ntest_iou_sum=0.0\nfor tidx in range(test_count):\n    test_entry=test_data[tidx]\n    # train a net for that shape\n    shape_net2=NeuralHighlighter(depth=5, width=256, out_dim=2, input_dim=3).cuda()\n    shape_coords2=test_entry[\"coords\"]\n    aff_main2=test_entry[\"affordances\"][0]\n    prompt_main2=f\"A 3D render of a gray {test_entry['shape_class']} with highlighted {aff_main2}\"\n\n    txt_feats_main2=encode_text(clip_model2, prompt_main2, device=\"cuda\")\n    test_renderer=MultiViewPointCloudRenderer(image_size=256, base_dist=20, base_elev=10, device=\"cuda\")\n\n    shape_net2=optimize_point_cloud(\n        points=shape_coords2,\n        clip_model=clip_model2,\n        renderer=test_renderer,\n        encoded_text=txt_feats_main2,\n        log_dir=\"./test_tmp\",\n        num_iterations=200,\n        device=\"cuda\",\n        n_views=2\n    )\n\n    # measure iou across all affs with best_strat, best_th\n    sum_tiou=0.0\n    c3=0\n    with torch.no_grad():\n        pclass_test=shape_net2(shape_coords2)\n        highlight_prob_test= pclass_test[:,0]\n    for aff_tst in test_entry[\"affordances\"]:\n        gt_tst=(test_entry[\"labels_dict\"][aff_tst]>0.5).long()\n        bin_preds_tst=(highlight_prob_test>=best_th).long()\n        iou_test=compute_mIoU(bin_preds_tst, gt_tst)\n        sum_tiou+=iou_test\n        c3+=1\n    shape_avg_tiou= sum_tiou/c3 if c3>0 else 0.0\n    test_iou_sum+=shape_avg_tiou\n\nfinal_test_mIoU = test_iou_sum/test_count if test_count>0 else 0.0\nprint(f\"[Test] Using best strategy={best_strat}, threshold={best_th}, final test mIoU={final_test_mIoU:.3f}\")\n\n# We can also visualize one test shape's multi-view using the highlight probability\nprint(\"\\nVisualizing multi-view for the last test shape with final threshold:\")\ntest_shape = test_data[test_count-1]\ncoords_test = test_shape[\"coords\"]\nwith torch.no_grad():\n    test_pred = shape_net2(coords_test)\n    highlight_sc = test_pred[:,0]\n\n# let's do a quick multi-view\ntest_cloud = test_renderer.create_point_cloud(\n    coords_test,\n    highlight_sc.unsqueeze(1)*torch.tensor([204/255,1.0,0.0],device=\"cuda\") +\n    (1.0 - highlight_sc.unsqueeze(1))*torch.tensor([180/255,180/255,180/255],device=\"cuda\")\n)\nrendered_testviews = test_renderer.render_all_views(test_cloud,n_views=4)\nimport matplotlib.pyplot as plt\nfig,axes=plt.subplots(1,len(rendered_testviews),figsize=(4*len(rendered_testviews),4))\nfor ax,(vname,imgT) in zip(axes, rendered_testviews.items()):\n    ax.imshow(imgT.cpu().numpy())\n    ax.set_title(vname)\n    ax.axis('off')\nplt.suptitle(f\"Test Shape {test_shape['shape_id']} - final threshold={best_th}\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T21:56:25.265284Z","iopub.execute_input":"2024-12-30T21:56:25.265711Z","iopub.status.idle":"2024-12-30T22:21:43.244210Z","shell.execute_reply.started":"2024-12-30T21:56:25.265675Z","shell.execute_reply":"2024-12-30T22:21:43.242993Z"}},"outputs":[{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:38,  5.20it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2390\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.42it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2372\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.36it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2178\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.42it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2238\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2230\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2319\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.37it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2233\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.42it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.1914\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2235\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2573\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.40it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2285\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.42it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2230\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2191\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.40it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2195\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.37it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2163\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2404\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2510\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2379\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.1887\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2625\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2185\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2499\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.1809\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2306\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.36it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2605\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:17,  5.45it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2256\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.41it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2273\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2098\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2151\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.40it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2549\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2263\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.42it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2355\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.37it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2301\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2347\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2178\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.1799\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.41it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2416\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2192\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.39it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2087\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2335\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.39it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2411\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2725\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.1893\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2208\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.1876\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2422\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2308\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.41it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2489\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2295\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2434\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:37,  5.34it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2197\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.41it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.1886\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2170\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:17,  5.46it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2094\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2256\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.38it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2313\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.39it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2181\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.40it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2327\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2284\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:17,  5.46it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.1885\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2302\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.1935\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2150\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:17,  5.45it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2357\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.41it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2211\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2310\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2278\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.43it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2205\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.37it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2330\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.42it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2352\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.1830\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2395\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2067\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:17,  5.46it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2224\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  1%|          | 2/200 [00:00<00:36,  5.35it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2188\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.1855\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.47it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2211\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.1897\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2064\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.41it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2238\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2106\n","output_type":"stream"},{"name":"stderr","text":" 51%|█████     | 102/200 [00:18<00:18,  5.44it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 100, Loss: -0.2393\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 200/200 [00:36<00:00,  5.46it/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\nModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=2, bias=True)\n  (19): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Iteration 0, Loss: -0.2164\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▎        | 25/200 [00:04<00:32,  5.47it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-cc5da2f23d2d>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mtxt_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_model2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mshape_renderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiViewPointCloudRenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_elev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             shape_net=optimize_point_cloud(\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0mpoints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape_coords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mclip_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip_model2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-82526437bf6b>\u001b[0m in \u001b[0;36moptimize_point_cloud\u001b[0;34m(points, clip_model, renderer, encoded_text, log_dir, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Create and render point cloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mpoint_cloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_point_cloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mrendered_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender_all_views\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_cloud\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoint_cloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_views\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;31m# Convert dictionary of images to tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mrendered_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/working/Affordance3DHighlighter/src/render/cloud_point_renderer.py\u001b[0m in \u001b[0;36mrender_all_views\u001b[0;34m(self, point_cloud, n_views)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mview_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviews\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_views\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenter_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_cloud\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mview_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/points/renderer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, point_clouds, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint_clouds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mfragments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrasterizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_clouds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# Construct weights based on the distance of a point to the true point.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/points/rasterizer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, point_clouds, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mPointFragments\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRasterization\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnamed\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \"\"\"\n\u001b[0;32m--> 159\u001b[0;31m         \u001b[0mpoints_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint_clouds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0mraster_settings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raster_settings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraster_settings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         idx, zbuf, dists2 = rasterize_points(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/points/rasterizer.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, point_clouds, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# to a different range.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eps\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         pts_view = cameras.get_world_to_view_transform(**kwargs).transform_points(\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0mpts_world\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/cameras.py\u001b[0m in \u001b[0;36mget_world_to_view_transform\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mworld_to_view_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_world_to_view_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mworld_to_view_transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/renderer/cameras.py\u001b[0m in \u001b[0;36mget_world_to_view_transform\u001b[0;34m(R, T)\u001b[0m\n\u001b[1;32m   1589\u001b[0m     \u001b[0;31m# Create a Transform3d object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0mT_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0mR_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mR_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch3d/transforms/transform3d.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, R, dtype, device, orthogonal_tol)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mdevice_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":14}]}