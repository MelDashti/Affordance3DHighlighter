{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!git clone https://github.com/amiralichangizi/3DHighlighter.git"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rqJobuCpQLi",
    "outputId": "281b69ef-7d5c-40e7-e9d1-c343706616ea"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/content/3DHighlighter')"
   ],
   "metadata": {
    "id": "fhLYzi952EEA"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d8vCbctxbPP4",
    "outputId": "55a100ed-7b85-4630-9e3f-e3ce98c37fff",
    "collapsed": true
   },
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!pip install kaolin==0.17.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.5.1_cu121.html"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "need_pytorch3d = False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d = True\n",
    "if need_pytorch3d:\n",
    "    pyt_version_str = torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "    version_str = \"\".join([\n",
    "        f\"py3{sys.version_info.minor}_cu\",\n",
    "        torch.version.cuda.replace(\".\", \"\"),\n",
    "        f\"_pyt{pyt_version_str}\"\n",
    "    ])\n",
    "    !pip install iopath\n",
    "    if sys.platform.startswith(\"linux\"):\n",
    "        print(\"Trying to install wheel for PyTorch3D\")\n",
    "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "        pip_list = !pip freeze\n",
    "        need_pytorch3d = not any(i.startswith(\"pytorch3d==\") for i in pip_list)\n",
    "    if need_pytorch3d:\n",
    "        print(f\"failed to find/install wheel for {version_str}\")\n",
    "if need_pytorch3d:\n",
    "    print(\"Installing PyTorch3D from source\")\n",
    "    !pip install ninja\n",
    "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sRNWfRMnIzuJ",
    "outputId": "39ed1f77-3f8e-499d-eb2b-8aecadf7c335",
    "ExecuteTime": {
     "end_time": "2024-12-26T14:58:53.585274Z",
     "start_time": "2024-12-26T14:58:48.836644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iopath in c:\\users\\asus\\anaconda3\\envs\\3dhighlighter\\lib\\site-packages (0.1.10)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\asus\\anaconda3\\envs\\3dhighlighter\\lib\\site-packages (from iopath) (4.12.2)\n",
      "Requirement already satisfied: portalocker in c:\\users\\asus\\anaconda3\\envs\\3dhighlighter\\lib\\site-packages (from iopath) (3.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\anaconda3\\envs\\3dhighlighter\\lib\\site-packages (from iopath) (4.67.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\asus\\anaconda3\\envs\\3dhighlighter\\lib\\site-packages (from portalocker->iopath) (308)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\anaconda3\\envs\\3dhighlighter\\lib\\site-packages (from tqdm->iopath) (0.4.6)\n",
      "failed to find/install wheel for py39_cu113_pyt1121\n",
      "Installing PyTorch3D from source\n",
      "Requirement already satisfied: ninja in c:\\users\\asus\\anaconda3\\envs\\3dhighlighter\\lib\\site-packages (1.11.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: \"'git+https://github.com/facebookresearch/pytorch3d.git@stable'\"\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install open3d"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zT9LfpcRXDHy",
    "outputId": "527d847c-60da-4e72-c096-81cbf9671f92"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!mkdir -p data/PittsburghBridge\n",
    "!wget -P data/PittsburghBridge https://dl.fbaipublicfiles.com/pytorch3d/data/PittsburghBridge/pointcloud.npz"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FTk44DGYYIBS",
    "outputId": "864b8bfd-a638-4f09-f520-d3f0fb75389c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "from src.mesh import Mesh\n",
    "from pytorch3d.structures import Pointclouds\n",
    "\n",
    "\n",
    "def load_3d_data(file_path, num_points=10000, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    Loads 3D data as PyTorch3D Pointclouds from either NPZ point cloud or OBJ mesh.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to either .npz point cloud or .obj mesh file\n",
    "        num_points: Number of points to sample if loading from mesh\n",
    "        device: Device to load data on\n",
    "\n",
    "    Returns:\n",
    "        Pointclouds object containing points and features\n",
    "    \"\"\"\n",
    "    file_ext = file_path.split('.')[-1].lower()\n",
    "\n",
    "    if file_ext == 'npz':\n",
    "        # Load NPZ point cloud directly like in the example\n",
    "        pointcloud = np.load(file_path)\n",
    "        verts = torch.Tensor(pointcloud['verts']).to(device)\n",
    "        rgb = torch.Tensor(pointcloud['rgb']).to(device)\n",
    "\n",
    "        # Subsample if needed\n",
    "        if len(verts) > num_points:\n",
    "            idx = torch.randperm(len(verts))[:num_points]\n",
    "            verts = verts[idx]\n",
    "            rgb = rgb[idx]\n",
    "\n",
    "        # Return both the points tensor and the Pointclouds object\n",
    "        point_cloud = Pointclouds(points=[verts], features=[rgb])\n",
    "        return verts, point_cloud  # Return both\n",
    "\n",
    "    elif file_ext == 'obj':\n",
    "        # Load mesh and sample points\n",
    "        mesh = Mesh(file_path)\n",
    "        vertices = mesh.vertices\n",
    "\n",
    "        # Sample random points\n",
    "        idx = torch.randperm(vertices.shape[0])[:num_points]\n",
    "        points = vertices[idx].to(device)\n",
    "\n",
    "        # Initialize with gray color\n",
    "        colors = torch.ones_like(points) * 0.7\n",
    "\n",
    "        return Pointclouds(points=[points], features=[colors])\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file format: {file_ext}. Only .npz and .obj are supported.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from src.save_results import save_renders, save_results\n",
    "from src.render.cloud_point_renderer import PointCloudRenderer\n",
    "from src.neural_highlighter import NeuralHighlighter\n",
    "from src.Clip.loss_function import clip_loss\n",
    "from src.Clip.clip_model import get_clip_model, encode_text, setup_clip_transforms\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constrain most sources of randomness\n",
    "# (some torch backwards functions within CLIP are non-determinstic)\n",
    "# Set a consistent seed for reproducibility\n",
    "seed = 0  # You can use any integer value\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def optimize_point_cloud(points, point_cloud, clip_model, renderer, encoded_text, log_dir: str, num_iterations=500,\n",
    "                         learning_rate=1e-4, device=\"cuda\"):\n",
    "    # Initialize network and optimizer\n",
    "    net = NeuralHighlighter(\n",
    "        depth=5,  # Number of hidden layers\n",
    "        width=256,  # Width of each layer\n",
    "        out_dim=2,  # Binary classification (highlight/no-highlight)\n",
    "        input_dim=3,  # 3D coordinates (x,y,z)\n",
    "        positional_encoding=False  # As recommended in the paper\n",
    "    ).to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "    render_engine = renderer.setup_renderer()\n",
    "\n",
    "    # Set up the transforms\n",
    "    clip_transform, augment_transform = setup_clip_transforms()\n",
    "\n",
    "    # Training loop\n",
    "    for i in tqdm(range(num_iterations)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Predict highlight probabilities\n",
    "        pred_class = net(points)\n",
    "\n",
    "        # Create colors based on predictions\n",
    "        highlight_color = torch.tensor([204 / 255, 1.0, 0.0]).to(device)\n",
    "        base_color = torch.tensor([180 / 255, 180 / 255, 180 / 255]).to(device)\n",
    "\n",
    "        colors = pred_class[:, 0:1] * highlight_color + pred_class[:, 1:2] * base_color\n",
    "\n",
    "        # Create and render point cloud\n",
    "        point_cloud = renderer.create_point_cloud(points, colors)\n",
    "        rendered_images = render_engine(point_cloud)\n",
    "\n",
    "        #Convert rendered images to CLIP format\n",
    "        rendered_images = rendered_images.permute(0, 3, 1, 2)  # [B, H, W, C] -> [B, C, H, W]\n",
    "\n",
    "        # Calculate CLIP loss\n",
    "        loss = clip_loss(rendered_images, encoded_text, clip_transform,\n",
    "                         augment_transform, clip_model)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"Iteration {i}, Loss: {loss.item():.4f}\")\n",
    "            save_renders(log_dir, i, rendered_images)\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def main(input_path, object_name, highlight_region,\n",
    "         num_points=10000, device=\"cuda\", output_dir=\"./output\"):\n",
    "    \"\"\"\n",
    "    Main function to process 3D data and generate highlighted regions.\n",
    "\n",
    "    Args:\n",
    "        input_path: Path to input 3D file (mesh or point cloud)\n",
    "        object_name: Name of the object for the prompt\n",
    "        highlight_region: Region to highlight\n",
    "        num_points: Number of points to use\n",
    "        device: Device to run on\n",
    "        output_dir: Directory to save outputs\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create output directory if it doesn't exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        # Load 3D data (either mesh or point cloud)\n",
    "        print(f\"Loading 3D data from {input_path}...\")\n",
    "        points, point_cloud = load_3d_data(input_path, num_points=num_points, device=device)\n",
    "        print(f\"Loaded {len(points)} points\")\n",
    "\n",
    "        # Setup CLIP model\n",
    "        print(\"Setting up CLIP model...\")\n",
    "        clip_model, preprocess, resolution = get_clip_model()\n",
    "\n",
    "        # Create and encode prompt\n",
    "        prompt = f\"A 3D render of a gray {object_name} with highlighted {highlight_region}\"\n",
    "        print(f\"Using prompt: {prompt}\")\n",
    "        text_features = encode_text(clip_model, prompt, device)\n",
    "\n",
    "        # Initialize renderer\n",
    "        print(\"Setting up renderer...\")\n",
    "        renderer = PointCloudRenderer(device=device)\n",
    "\n",
    "        # Optimize point cloud highlighting\n",
    "        print(\"Starting optimization...\")\n",
    "        net = optimize_point_cloud(\n",
    "            points=points,\n",
    "            point_cloud=point_cloud,\n",
    "            renderer=renderer,\n",
    "            clip_model=clip_model,\n",
    "            encoded_text=text_features,\n",
    "            device=device,\n",
    "            log_dir=output_dir\n",
    "        )\n",
    "\n",
    "        # Save results\n",
    "        print(\"Saving results...\")\n",
    "        save_results(\n",
    "            net=net,\n",
    "            points=points,\n",
    "            point_cloud=point_cloud,  # Add this\n",
    "            prompt=prompt,\n",
    "            output_dir=output_dir,\n",
    "            renderer=renderer\n",
    "        )\n",
    "\n",
    "        print(\"Processing complete!\")\n",
    "        return net, points\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in processing: {str(e)}\")\n",
    "        raise\n",
    "\n"
   ],
   "metadata": {
    "id": "E0SBrmlBkwib"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "main(\n",
    "    input_path=\"/content/3DHighlighter/data/PittsburghBridge/pointcloud.npz\",\n",
    "    object_name=\"Bridge\",\n",
    "    highlight_region=\"floor\",\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uD_gYzdOpy-t",
    "outputId": "d0563f73-0957-4301-d62e-4937f39216e6"
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
