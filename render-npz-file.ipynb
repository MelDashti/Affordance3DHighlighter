{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30823,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#Example NPZ FILE\n",
    "!mkdir -p data/PittsburghBridge\n",
    "!wget -P data/PittsburghBridge https://dl.fbaipublicfiles.com/pytorch3d/data/PittsburghBridge/pointcloud.npz"
   ],
   "metadata": {
    "trusted": true,
    "id": "8MuFM-8SXLTy"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "need_pytorch3d = False\n",
    "try:\n",
    "    import pytorch3d\n",
    "except ModuleNotFoundError:\n",
    "    need_pytorch3d = True\n",
    "if need_pytorch3d:\n",
    "    pyt_version_str = torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n",
    "    version_str = \"\".join([\n",
    "        f\"py3{sys.version_info.minor}_cu\",\n",
    "        torch.version.cuda.replace(\".\", \"\"),\n",
    "        f\"_pyt{pyt_version_str}\"\n",
    "    ])\n",
    "    !pip install iopath\n",
    "    if sys.platform.startswith(\"linux\"):\n",
    "        print(\"Trying to install wheel for PyTorch3D\")\n",
    "        !pip install --no-index --no-cache-dir pytorch3d -f https://dl.fbaipublicfiles.com/pytorch3d/packaging/wheels/{version_str}/download.html\n",
    "        pip_list = !pip freeze\n",
    "        need_pytorch3d = not any(i.startswith(\"pytorch3d==\") for i in pip_list)\n",
    "    if need_pytorch3d:\n",
    "        print(f\"failed to find/install wheel for {version_str}\")\n",
    "if need_pytorch3d:\n",
    "    print(\"Installing PyTorch3D from source\")\n",
    "    !pip install ninja\n",
    "    !pip install 'git+https://github.com/facebookresearch/pytorch3d.git@stable'"
   ],
   "metadata": {
    "id": "sRNWfRMnIzuJ",
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "15a1496c-0fcd-4d9d-c9e7-0e30be55a486"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from pytorch3d.structures import Pointclouds\n",
    "\n",
    "def bounding_sphere_normalize(points: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    points: (N,3) tensor of point coords\n",
    "    Return normalized points in a unit sphere centered at origin.\n",
    "    \"\"\"\n",
    "    center = points.mean(dim=0, keepdim=True)\n",
    "    max_dist = (points - center).norm(p=2, dim=1).max()\n",
    "    points_normed = (points - center) / max_dist\n",
    "    return points_normed\n",
    "\n",
    "\n",
    "def load_3d_data(file_path, num_points=10000, device=\"cuda\", do_normalize=True):\n",
    "    # Load NPZ point cloud directly like in the example\n",
    "    pointcloud = np.load(file_path)\n",
    "    verts = torch.Tensor(pointcloud['points']).to(device)\n",
    "\n",
    "    # Check if 'colors' key exists, if not, create a default color\n",
    "    if 'colors' in pointcloud:\n",
    "        rgb = torch.Tensor(pointcloud['colors']).to(device)\n",
    "    else:\n",
    "        rgb = torch.ones(verts.shape[0], 3, device=device)  # Default to white color\n",
    "\n",
    "    # Subsample if needed\n",
    "    if len(verts) > num_points:\n",
    "        idx = torch.randperm(len(verts))[:num_points]\n",
    "        verts = verts[idx]\n",
    "        rgb = rgb[idx]\n",
    "\n",
    "    if do_normalize:\n",
    "        verts = bounding_sphere_normalize(verts)\n",
    "\n",
    "    # Return both the points tensor and the Pointclouds object\n",
    "    point_cloud = Pointclouds(points=[verts], features=[rgb])\n",
    "    return point_cloud  # Return both"
   ],
   "metadata": {
    "id": "fxo1SjSH2NHm",
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from itertools import islice\n",
    "\n",
    "import torch\n",
    "from pytorch3d.structures import Pointclouds\n",
    "from pytorch3d.renderer import (\n",
    "    look_at_view_transform,\n",
    "    FoVOrthographicCameras,\n",
    "    FoVPerspectiveCameras,\n",
    "    PointsRasterizationSettings,\n",
    "    PointsRenderer,\n",
    "    PointsRasterizer,\n",
    "    AlphaCompositor\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "class MultiViewPointCloudRenderer:\n",
    "    def __init__(self, image_size=512, base_dist=20, base_elev=10, base_azim=0,\n",
    "                 device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        self.device = device\n",
    "        self.image_size = image_size\n",
    "        self.base_dist = base_dist\n",
    "        self.base_elev = base_elev\n",
    "        self.base_azim = base_azim\n",
    "        self.to_tensor = T.Compose([\n",
    "            T.Resize((image_size, image_size)),\n",
    "            T.ToTensor()\n",
    "        ])\n",
    "\n",
    "        # Define the settings for rasterization\n",
    "        self.raster_settings = PointsRasterizationSettings(\n",
    "            image_size=image_size,\n",
    "            radius=0.008,\n",
    "            points_per_pixel=20\n",
    "        )\n",
    "\n",
    "        # Define all views relative to base view\n",
    "        self.views = {\n",
    "            'Default': (base_dist, base_elev, base_azim),\n",
    "            'Y_90deg': (base_dist, base_elev, base_azim + 90),\n",
    "            'Y_180deg': (base_dist, base_elev, base_azim + 180),\n",
    "            'Y_-90deg': (base_dist, base_elev, base_azim - 90),\n",
    "            'X_90deg': (base_dist, base_elev + 90, base_azim),\n",
    "            'X_-90deg': (base_dist, base_elev - 90, base_azim),\n",
    "                    }\n",
    "\n",
    "\n",
    "    def get_center_point(self, point_cloud):\n",
    "        \"\"\"Calculate the center point of the point cloud\"\"\"\n",
    "        points = point_cloud.points_packed()\n",
    "        center = torch.mean(points, dim=0)\n",
    "        return center.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    def create_renderer(self, dist, elev, azim, center_point, background_color=(0, 0, 0)):\n",
    "        \"\"\"Create a renderer for specific camera parameters\"\"\"\n",
    "        # Use the center point as the 'at' parameter\n",
    "        R, T = look_at_view_transform(\n",
    "            dist=dist,\n",
    "            elev=elev,\n",
    "            azim=azim,\n",
    "            at=center_point,  # Look at the center of the point cloud\n",
    "        )\n",
    "        cameras = FoVPerspectiveCameras(\n",
    "        device=self.device,\n",
    "        R=R,\n",
    "        T=T\n",
    "        )\n",
    "\n",
    "        rasterizer = PointsRasterizer(cameras=cameras, raster_settings=self.raster_settings)\n",
    "        renderer = PointsRenderer(\n",
    "            rasterizer=rasterizer,\n",
    "            compositor=AlphaCompositor(background_color=background_color)\n",
    "        )\n",
    "        return renderer\n",
    "\n",
    "    def load_background(self, background_path):\n",
    "        bg_image = Image.open(background_path)\n",
    "        bg_tensor = self.to_tensor(bg_image).to(self.device)\n",
    "        return bg_tensor.permute(1, 2, 0)  # Convert to HWC format\n",
    "\n",
    "    def render_all_views(self, point_cloud, n_views=6, background_path=None,background_color=(0, 0, 0)):\n",
    "        images = {}\n",
    "        center_point = self.get_center_point(point_cloud)\n",
    "\n",
    "        if background_path: background = self.load_background(background_path)\n",
    "        else:\n",
    "            background = None\n",
    "\n",
    "        for view_name, (dist, elev, azim) in islice(self.views.items(), n_views):\n",
    "            renderer = self.create_renderer(dist, elev, azim, center_point,background_color=background_color)\n",
    "            image = renderer(point_cloud)\n",
    "\n",
    "            if background is not None:\n",
    "                # Create binary mask from points\n",
    "                mask = torch.any(image[0, ..., :3] > 0, dim=-1).float()\n",
    "                mask = mask.unsqueeze(-1).expand(-1, -1, 3)\n",
    "                composite = (image[0, ..., :3] * mask) + (background * (1 - mask))\n",
    "                images[view_name] = composite\n",
    "            else:\n",
    "                images[view_name] = image[0, ..., :3]\n",
    "\n",
    "        return images"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-10T12:40:51.144545Z",
     "iopub.execute_input": "2025-01-10T12:40:51.144972Z",
     "iopub.status.idle": "2025-01-10T12:40:51.162323Z",
     "shell.execute_reply.started": "2025-01-10T12:40:51.144937Z",
     "shell.execute_reply": "2025-01-10T12:40:51.161309Z"
    },
    "id": "wuyQBUuVXLT3"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "def save_results(point_cloud, renderer,n_views,device,output_dir,output_name):\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    rendered_images = renderer.render_all_views(point_cloud=point_cloud, n_views=n_views,background_color = (1,1,1))\n",
    "    # Convert dictionary of images to tensor\n",
    "    rendered_tensor = []\n",
    "    for name, img in rendered_images.items():\n",
    "        rendered_tensor.append(img.to(device))\n",
    "    rendered_tensor = torch.stack(rendered_tensor)\n",
    "\n",
    "    # Convert rendered images to CLIP format\n",
    "    rendered_images = rendered_tensor.permute(0, 3, 1, 2)  # [B, H, W, C] -> [B, C, H, W]\n",
    "\n",
    "    # Convert to uint8 range [0, 255]\n",
    "    rendered_images = (rendered_images * 255).clamp(0, 255).to(torch.uint8)\n",
    "\n",
    "    # Save rendered image using torchvision\n",
    "    torchvision.utils.save_image(\n",
    "        rendered_images.float() / 255.0,  # Convert back to [0,1] range\n",
    "        os.path.join(output_dir, output_name),\n",
    "         normalize=False  # We've already normalized the values\n",
    "     )"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-10T12:25:45.189872Z",
     "iopub.execute_input": "2025-01-10T12:25:45.190159Z",
     "iopub.status.idle": "2025-01-10T12:25:45.195735Z",
     "shell.execute_reply.started": "2025-01-10T12:25:45.190138Z",
     "shell.execute_reply": "2025-01-10T12:25:45.194700Z"
    },
    "id": "h6AZlqSYXLT4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "device=\"cuda\"\n",
    "\n",
    "point_cloud = load_3d_data(\n",
    "    \"/content/highlighted_points.npz\",\n",
    "    num_points=100000\n",
    ")\n",
    "\n",
    "\n",
    "renderer = MultiViewPointCloudRenderer(\n",
    "    image_size=1024,\n",
    "    base_dist=2.5,  # Your default view distance\n",
    "    base_elev=10,  # Your default elevation\n",
    "    base_azim=0,  # Your default azimuth\n",
    "    device=device\n",
    ")\n",
    "\n",
    "save_results(\n",
    "    point_cloud=point_cloud,\n",
    "    renderer=renderer,\n",
    "    n_views=6,\n",
    "    output_dir=\"./output\",\n",
    "    output_name=\"point_cloud2.png\",\n",
    "    device=device\n",
    ")"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-10T12:40:55.624638Z",
     "iopub.execute_input": "2025-01-10T12:40:55.624923Z",
     "iopub.status.idle": "2025-01-10T12:40:56.626927Z",
     "shell.execute_reply.started": "2025-01-10T12:40:55.624902Z",
     "shell.execute_reply": "2025-01-10T12:40:56.626223Z"
    },
    "id": "kC0TUM0pXLT4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from pytorch3d.vis.plotly_vis import plot_scene\n",
    "plot_scene({\n",
    "    \"Pointcloud\": {\n",
    "        \"person\": point_cloud\n",
    "    }\n",
    "})"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-01-10T12:29:14.334120Z",
     "iopub.execute_input": "2025-01-10T12:29:14.334432Z",
     "iopub.status.idle": "2025-01-10T12:29:14.462576Z",
     "shell.execute_reply.started": "2025-01-10T12:29:14.334408Z",
     "shell.execute_reply": "2025-01-10T12:29:14.461780Z"
    },
    "id": "QzDG3gYTXLT5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "outputId": "441cbe63-3e9d-4a8e-a872-6d3ff20a52f6"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "# Load the .ply file\n",
    "pcd = o3d.io.read_point_cloud(\"/content/gt_pointcloud_contain.ply\")\n",
    "\n",
    "# Extract points and colors\n",
    "points = np.asarray(pcd.points)\n",
    "colors = np.asarray(pcd.colors)\n",
    "\n",
    "# Lighten the base colors (adjust factor as needed)\n",
    "colors = colors * 1.5  # Increase brightness by 50%\n",
    "colors = np.clip(colors, 0, 1)  # Clip values to the valid range [0, 1]\n",
    "\n",
    "# Save to .npz\n",
    "np.savez_compressed(\"output.npz\", points=points, colors=colors)"
   ],
   "metadata": {
    "id": "PN4773gwSTNT"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ground truth was saved as ply file so we convert npz"
   ],
   "metadata": {
    "id": "MeBeo5VDY6sq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install open3d numpy"
   ],
   "metadata": {
    "collapsed": true,
    "id": "-JjJHCWfZL8C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1ebf9826-3726-4d79-d765-4f3fca58a8e4"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "calculation of IOU"
   ],
   "metadata": {
    "id": "jEBbUv64beQr"
   }
  },
  {
   "cell_type": "code",
   "source": "!git clone https://github.com/amiralichangizi/Affordance3DHighlighter.git\n",
   "metadata": {
    "id": "FFo6KKmA98CT",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0ab6e9aa-614c-43a6-cfbb-5609a4dc106e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install gdown\n",
    "!gdown --id 1siZtGusB1LfQVapTvNOiYi8aeKKAgcDF\n",
    "!unzip full-shape.zip -d /content/Affordance3DHighlighter/data/"
   ],
   "metadata": {
    "id": "Bk1eAk0n-ANm",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "626bfc2d-942a-4a67-e15e-9354ed589d9c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.chdir('/content/Affordance3DHighlighter')"
   ],
   "metadata": {
    "id": "QS-XzBW1-7lE"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Find the previously used shape in the dataset for aiou calculation"
   ],
   "metadata": {
    "id": "oVqqH7yYvPED"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from src.data_loader_fullshape import FullShapeDataset, create_dataset_splits\n",
    "\n",
    "# Load the dataset\n",
    "pkl_path = \"/content/Affordance3DHighlighter/data/full_shape_train_data.pkl\"\n",
    "device = \"cpu\"  # or \"cuda\"\n",
    "# Instantiate the dataset\n",
    "dataset = FullShapeDataset(pkl_path, device=device, target_classes=['Door'], target_affordances = ['openable', 'pushable', 'pull'])\n",
    "train_data, val_data, test_data = create_dataset_splits(dataset, val_ratio=0.1, test_ratio=0.1)\n",
    "\n",
    "# Print out your current dataset configuration\n",
    "print(\"Current dataset target classes:\", dataset.target_classes)\n",
    "print(\"Current dataset target affordances:\", dataset.target_affordances)\n",
    "\n",
    "# Let's see what shapes we actually have\n",
    "print(\"\\nSample of available shape IDs:\")\n",
    "for i in range(min(5, len(dataset))):\n",
    "    entry = dataset[i]\n",
    "    print(f\"Shape ID: {entry['shape_id']}\")\n",
    "    print(f\"Class: {entry['shape_class']}\")\n",
    "    print(f\"Affordances: {entry['affordances']}\")\n",
    "    print(\"---\")\n",
    "\n",
    "def find_shape_in_all_splits(shape_id, train_data, val_data, test_data):\n",
    "    \"\"\"\n",
    "    Search for a specific shape ID across all dataset splits.\n",
    "    Returns the shape entry and which split it was found in.\n",
    "    \"\"\"\n",
    "    # Check training set\n",
    "    for idx in range(len(train_data)):\n",
    "        entry = train_data[idx]\n",
    "        if entry['shape_id'] == shape_id:\n",
    "            return entry, 'train', idx\n",
    "\n",
    "    # Check validation set\n",
    "    for idx in range(len(val_data)):\n",
    "        entry = val_data[idx]\n",
    "        if entry['shape_id'] == shape_id:\n",
    "            return entry, 'split', idx\n",
    "\n",
    "    # Check test set\n",
    "    for idx in range(len(test_data)):\n",
    "        entry = test_data[idx]\n",
    "        if entry['shape_id'] == shape_id:\n",
    "            return entry, 'test', idx\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "# Search for your specific shape\n",
    "target_shape_id = \"f649133ee152f0c4535dab46efb28e27\"\n",
    "shape_entry, split_found, idx = find_shape_in_all_splits(target_shape_id, train_data, val_data, test_data)\n",
    "\n",
    "if shape_entry is not None:\n",
    "    print(f\"Found shape {target_shape_id} in {split_found} split at index {idx}\")\n",
    "    print(f\"Shape class: {shape_entry['shape_class']}\")\n",
    "    print(f\"Affordances: {shape_entry['affordances']}\")\n",
    "    print(f\"Point cloud shape: {shape_entry['coords'].shape}\")\n",
    "    print(\"\\nFull shape entry:\")\n",
    "    for key, value in shape_entry.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            print(f\"{key}: Tensor of shape {value.shape}\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")\n",
    "else:\n",
    "    # If not found, let's check the original dataset before splitting\n",
    "    for idx in range(len(dataset)):\n",
    "        entry = dataset[idx]\n",
    "        if entry['shape_id'] == target_shape_id:\n",
    "            print(f\"Found shape in original dataset at index {idx}\")\n",
    "            print(f\"Shape class: {entry['shape_class']}\")\n",
    "            print(f\"Affordances: {entry['affordances']}\")\n",
    "            print(f\"Point cloud shape: {entry['coords'].shape}\")\n",
    "            break\n",
    "    else:\n",
    "        print(f\"Shape {target_shape_id} not found in any split or the original dataset!\")"
   ],
   "metadata": {
    "id": "Mv8j2iKd9x4q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "82179e11-973c-4a6c-c65a-42cd63fd874d"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_highlight_iou(shape_entry, highlighted_npz_path, threshold=0.0):\n",
    "    \"\"\"\n",
    "    Compare ground truth labels with highlighted predictions and compute IoU\n",
    "\n",
    "    Args:\n",
    "        shape_entry: The dataset entry containing ground truth labels\n",
    "        highlighted_npz_path: Path to the NPZ file with highlighted predictions\n",
    "        threshold: Threshold for converting prediction probabilities to binary\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing IoU and related metrics\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "\n",
    "    # Get ground truth labels\n",
    "    gt_labels = shape_entry['labels_dict']['contain'].cpu().numpy()\n",
    "    gt_binary = (gt_labels > 0).astype(int)\n",
    "\n",
    "    # Load highlighted predictions\n",
    "    pred_data = np.load('/content/highlighted_points.npz')\n",
    "    pred_points = pred_data['points']         # shape (N, 3)\n",
    "    pred_probs = pred_data['probabilities']   # shape (N, 2) typically\n",
    "\n",
    "    # Get the highlight probabilities (assuming first column is highlight prob)\n",
    "    highlight_probs = pred_probs[:, 0]\n",
    "    pred_binary = (highlight_probs >= threshold).astype(int)\n",
    "\n",
    "    # Verify shapes match\n",
    "    coords = shape_entry['coords'].cpu().numpy()\n",
    "    if coords.shape == pred_points.shape:\n",
    "        print(\"Points match exactly in shape!\")\n",
    "        # Direct comparison\n",
    "        intersection = np.sum((pred_binary == 1) & (gt_binary == 1))\n",
    "        union = np.sum((pred_binary == 1) | (gt_binary == 1))\n",
    "        iou = intersection / union if union > 0 else 0.0\n",
    "\n",
    "    # else:\n",
    "    #     print(\"Points don't match exactly, using nearest neighbor matching...\")\n",
    "    #     # Use KD-tree for point matching\n",
    "    #     from scipy.spatial import cKDTree\n",
    "    #     tree = cKDTree(coords)\n",
    "    #     _, nn_indices = tree.query(pred_points)\n",
    "\n",
    "    #     # Align ground truth to prediction ordering\n",
    "    #     aligned_gt = gt_binary[nn_indices]\n",
    "\n",
    "    #     # Compute IoU\n",
    "    #     intersection = np.sum((pred_binary == 1) & (aligned_gt == 1))\n",
    "    #     union = np.sum((pred_binary == 1) | (aligned_gt == 1))\n",
    "    #     iou = intersection / union if union > 0 else 0.0\n",
    "\n",
    "    # Compute additional metrics\n",
    "    metrics = {\n",
    "        'iou': iou,\n",
    "        'intersection': intersection,\n",
    "        'union': union,\n",
    "        'gt_positive': np.sum(gt_binary),\n",
    "        'pred_positive': np.sum(pred_binary),\n",
    "        'total_points': len(gt_binary)\n",
    "    }\n",
    "\n",
    "    return metrics\n",
    "\n",
    "# Usage example:\n",
    "highlighted_npz_path = \"path/to/your/highlighted_points.npz\"  # Replace with your NPZ file path\n",
    "metrics = compute_highlight_iou(shape_entry, highlighted_npz_path)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nResults:\")\n",
    "print(f\"IoU Score: {metrics['iou']:.4f}\")\n",
    "print(f\"Intersection: {metrics['intersection']} points\")\n",
    "print(f\"Union: {metrics['union']} points\")\n",
    "print(f\"Ground Truth Positive Points: {metrics['gt_positive']}\")\n",
    "print(f\"Predicted Positive Points: {metrics['pred_positive']}\")\n",
    "print(f\"Total Points: {metrics['total_points']}\")\n"
   ],
   "metadata": {
    "id": "kaHg0D48WVTs",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "80aafb0a-4e70-4938-ae9f-d7cb1058bab0"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_average_iou(shape_entry, highlighted_npz_path, threshold_start=0.001, threshold_end=0.99, threshold_step=0.01):\n",
    "    \"\"\"\n",
    "    Compute average IoU across different thresholds\n",
    "\n",
    "    Args:\n",
    "        shape_entry: Dataset entry containing ground truth labels\n",
    "        highlighted_npz_path: Path to NPZ file with predictions\n",
    "        threshold_start: Starting threshold value (default: 0.0)\n",
    "        threshold_end: Ending threshold value (default: 0.99)\n",
    "        threshold_step: Step size for threshold increments (default: 0.01)\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing aIoU and IoUs at each threshold\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    from scipy.spatial import cKDTree\n",
    "\n",
    "    # Get ground truth labels\n",
    "    gt_labels = shape_entry['labels_dict']['openable'].cpu().numpy()\n",
    "    gt_binary = (gt_labels > 0).astype(int)\n",
    "    coords = shape_entry['coords'].cpu().numpy()\n",
    "\n",
    "    # Load highlighted predictions\n",
    "    pred_data = np.load(highlighted_npz_path)\n",
    "    pred_points = pred_data['points']\n",
    "    pred_probs = pred_data['probabilities']\n",
    "    highlight_probs = pred_probs[:, 0]  # Assuming first column is highlight probability\n",
    "\n",
    "    # Check if points need alignment\n",
    "    if coords.shape != pred_points.shape:\n",
    "        print(\"Aligning points using nearest neighbors...\")\n",
    "        tree = cKDTree(coords)\n",
    "        _, nn_indices = tree.query(pred_points)\n",
    "        gt_binary = gt_binary[nn_indices]\n",
    "\n",
    "    # Generate thresholds\n",
    "    thresholds = np.arange(threshold_start, threshold_end + threshold_step, threshold_step)\n",
    "    ious = []\n",
    "\n",
    "    print(\"Computing IoUs for different thresholds...\")\n",
    "    for threshold in thresholds:\n",
    "        # Binarize predictions at this threshold\n",
    "        pred_binary = (highlight_probs >= threshold).astype(int)\n",
    "\n",
    "        # Compute IoU\n",
    "        intersection = np.sum((pred_binary == 1) & (gt_binary == 1))\n",
    "        union = np.sum((pred_binary == 1) | (gt_binary == 1))\n",
    "        iou = intersection / union if union > 0 else 0.0\n",
    "        ious.append(iou)\n",
    "\n",
    "    # Convert to numpy array for easier manipulation\n",
    "    ious = np.array(ious)\n",
    "\n",
    "    # Compute average IoU\n",
    "    aiou = np.mean(ious)\n",
    "\n",
    "    # Find best threshold and its IoU\n",
    "    best_idx = np.argmax(ious)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "    best_iou = ious[best_idx]\n",
    "\n",
    "    results = {\n",
    "        'aiou': aiou,\n",
    "        'thresholds': thresholds,\n",
    "        'ious': ious,\n",
    "        'best_threshold': best_threshold,\n",
    "        'best_iou': best_iou\n",
    "    }\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nResults:\")\n",
    "    print(f\"Average IoU (aIoU): {aiou:.4f}\")\n",
    "    print(f\"Best IoU: {best_iou:.4f} at threshold {best_threshold:.2f}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "# Optional: Visualize the IoU curve\n",
    "def plot_iou_curve(results):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results['thresholds'], results['ious'], 'b-', label='IoU')\n",
    "    plt.axhline(y=results['aiou'], color='r', linestyle='--', label=f'aIoU = {results[\"aiou\"]:.4f}')\n",
    "    plt.plot(results['best_threshold'], results['best_iou'], 'go',\n",
    "             label=f'Best IoU = {results[\"best_iou\"]:.4f} at {results[\"best_threshold\"]:.2f}')\n",
    "\n",
    "    plt.xlabel('Threshold')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.title('IoU vs Threshold')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Usage example:\n",
    "highlighted_npz_path = \"/content/highlighted_points.npz\"  # Replace with your NPZ file path\n",
    "results = compute_average_iou(shape_entry, highlighted_npz_path)\n",
    "\n",
    "# Plot the results\n",
    "plot_iou_curve(results)"
   ],
   "metadata": {
    "id": "QY3kjGRRa3_M",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "outputId": "7f55772f-8a6d-41b3-81c8-331b5f19973b"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
